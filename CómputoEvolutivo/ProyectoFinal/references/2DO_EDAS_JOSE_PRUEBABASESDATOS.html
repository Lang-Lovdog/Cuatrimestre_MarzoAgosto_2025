<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>INICIALIZAR LABELS</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/libs/clipboard/clipboard.min.js"></script>
<script src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/libs/quarto-html/popper.min.js"></script>
<script src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/libs/quarto-html/anchor.min.js"></script>
<link href="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/libs/bootstrap/bootstrap-c00b9eaeb1bcd663ab72854ce00933b0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#edas-exploratorio-inicial-base-sin-limpiar" id="toc-edas-exploratorio-inicial-base-sin-limpiar" class="nav-link active" data-scroll-target="#edas-exploratorio-inicial-base-sin-limpiar">EDAS EXPLORATORIO INICIAL BASE SIN LIMPIAR</a></li>
  <li><a href="#prueba-quanttile-trasnformer" id="toc-prueba-quanttile-trasnformer" class="nav-link" data-scroll-target="#prueba-quanttile-trasnformer">PRUEBA QUANTTILE TRASNFORMER</a></li>
  <li><a href="#prueba-2" id="toc-prueba-2" class="nav-link" data-scroll-target="#prueba-2">PRUEBA 2</a></li>
  <li><a href="#bloque-1-eda-y-preparacion-de-datos" id="toc-bloque-1-eda-y-preparacion-de-datos" class="nav-link" data-scroll-target="#bloque-1-eda-y-preparacion-de-datos">BLOQUE 1 EDA Y PREPARACION DE DATOS</a></li>
  <li><a href="#bloque-2-selección-de-características-con-eda-wrapper" id="toc-bloque-2-selección-de-características-con-eda-wrapper" class="nav-link" data-scroll-target="#bloque-2-selección-de-características-con-eda-wrapper">Bloque 2: Selección de Características con EDA Wrapper</a></li>
  <li><a href="#pruebas-bloque-2" id="toc-pruebas-bloque-2" class="nav-link" data-scroll-target="#pruebas-bloque-2">PRUEBAS BLOQUE 2</a></li>
  <li><a href="#prueba-3" id="toc-prueba-3" class="nav-link" data-scroll-target="#prueba-3">PRUEBA 3</a></li>
  <li><a href="#prueba-de-rejilla-para-seleccion-de-modelo" id="toc-prueba-de-rejilla-para-seleccion-de-modelo" class="nav-link" data-scroll-target="#prueba-de-rejilla-para-seleccion-de-modelo">PRUEBA DE REJILLA PARA SELECCION DE MODELO</a></li>
  <li><a href="#prueba-con-modelo-obtenido" id="toc-prueba-con-modelo-obtenido" class="nav-link" data-scroll-target="#prueba-con-modelo-obtenido">PRUEBA CON MODELO OBTENIDO</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="2DO_EDAS_JOSE_PRUEBABASESDATOS.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">INICIALIZAR LABELS</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div id="cell-1" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Etiquetas separadas por punto y coma</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> <span class="st">"Marital status;Application mode;Application order;Course;Daytime/evening attendance;Previous qualification;Previous qualification (grade);Nacionality;Mother's qualification;Father's qualification;Mother's occupation;Father's occupation;Admission grade;Displaced;Educational special needs;Debtor;Tuition fees up to date;Gender;Scholarship holder;Age at enrollment;International;Curricular units 1st sem (credited);Curricular units 1st sem (enrolled);Curricular units 1st sem (evaluations);Curricular units 1st sem (approved);Curricular units 1st sem (grade);Curricular units 1st sem (without evaluations);Curricular units 2nd sem (credited);Curricular units 2nd sem (enrolled);Curricular units 2nd sem (evaluations);Curricular units 2nd sem (approved);Curricular units 2nd sem (grade);Curricular units 2nd sem (without evaluations);Unemployment rate;Inflation rate;GDP;Target"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Convertir etiquetas en lista</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>column_names <span class="op">=</span> labels.split(<span class="st">";"</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar el archivo CSV sin encabezados</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>ruta_archivo <span class="op">=</span> <span class="st">"Data_fil.csv"</span>  <span class="co"># Reemplaza con la ruta real de tu archivo</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>Data_fil <span class="op">=</span> pd.read_csv(ruta_archivo, header<span class="op">=</span><span class="va">None</span>, names<span class="op">=</span>column_names)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Guardar el nuevo DataFrame con encabezados en un nuevo archivo CSV</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>archivo_salida <span class="op">=</span> <span class="st">"archivo_con_labels.csv"</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>Data_fil.to_csv(archivo_salida, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Imprimir el contenido del nuevo archivo para verificar</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>df_verificado <span class="op">=</span> pd.read_csv(archivo_salida)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_verificado.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Marital status  Application mode  Application order  Course  \
0               1                 1                  1    9500   
1               1                43                  1    9500   
2               1                 1                  1    9773   
3               1                17                  2    9254   
4               1                17                  1    9070   

   Daytime/evening attendance  Previous qualification  \
0                           1                       1   
1                           1                       1   
2                           1                       1   
3                           1                       1   
4                           1                       1   

   Previous qualification (grade)  Nacionality  Mother's qualification  \
0                           132.0            1                      19   
1                           120.0            1                       1   
2                           150.0            1                      19   
3                           141.0            1                       1   
4                           119.0            1                      38   

   Father's qualification  ...  Curricular units 2nd sem (credited)  \
0                       1  ...                                    0   
1                       1  ...                                    0   
2                      38  ...                                    0   
3                       4  ...                                    0   
4                      19  ...                                    0   

   Curricular units 2nd sem (enrolled)  \
0                                    8   
1                                    8   
2                                    6   
3                                    6   
4                                    6   

   Curricular units 2nd sem (evaluations)  \
0                                       9   
1                                      15   
2                                       6   
3                                       9   
4                                       7   

   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \
0                                    8                         15.683333   
1                                    7                         11.571429   
2                                    6                         13.666667   
3                                    4                         13.500000   
4                                    5                         11.000000   

   Curricular units 2nd sem (without evaluations)  Unemployment rate  \
0                                               0               11.1   
1                                               0               12.7   
2                                               0               12.7   
3                                               0               16.2   
4                                               0               15.5   

   Inflation rate   GDP    Target  
0             0.6  2.02  Graduate  
1             3.7 -1.70  Graduate  
2             3.7 -1.70  Graduate  
3             0.3 -0.92  Graduate  
4             2.8 -4.06   Dropout  

[5 rows x 37 columns]</code></pre>
</div>
</div>
<section id="edas-exploratorio-inicial-base-sin-limpiar" class="level1">
<h1>EDAS EXPLORATORIO INICIAL BASE SIN LIMPIAR</h1>
<div id="cell-3" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Análisis Exploratorio de Datos - sonar.csv</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar el archivo CSV</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"Data_fil.csv"</span>, header<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Asignar nombres de columnas</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>df.columns <span class="op">=</span> [<span class="ss">f"Feature_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">36</span>)] <span class="op">+</span> [<span class="st">"Target"</span>]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Vista general del dataset</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Vista general del dataset:"</span>)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.head())</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Forma del dataset:"</span>, df.shape)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Tipos de datos</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Tipos de datos:"</span>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.dtypes)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificación de valores nulos</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Valores nulos por columna:"</span>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.isnull().<span class="bu">sum</span>())</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Estadísticas descriptivas</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Estadísticas descriptivas:"</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.describe())</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Histograma de las primeras 10 características</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>df.iloc[:, :<span class="dv">10</span>].hist(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>), bins<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Histogramas de las primeras 10 características"</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribución de la variable objetivo</span></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Distribución de la variable objetivo:"</span>)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[<span class="st">"Target"</span>].value_counts())</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span><span class="st">"Target"</span>, data<span class="op">=</span>df)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribución de la variable objetivo"</span>)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Matriz de correlación</span></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> df.iloc[:, :<span class="op">-</span><span class="dv">1</span>].corr()</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr_matrix, cmap<span class="op">=</span><span class="st">"coolwarm"</span>, annot<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Matriz de correlación"</span>)</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Boxplots de las primeras 10 características</span></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>    sns.boxplot(y<span class="op">=</span>df[<span class="ss">f"Feature_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>])</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"Feature_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a><span class="co">## Reducción de dimensionalidad con PCA</span></span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a><span class="co">#X = df.iloc[:, :-1]</span></span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a><span class="co">#y = df["Target"]</span></span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a><span class="co">## Estandarizar los datos</span></span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a><span class="co">#scaler = StandardScaler()</span></span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a><span class="co">#X_scaled = scaler.fit_transform(X)</span></span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a><span class="co"># Aplicar PCA</span></span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a><span class="co">#pca = PCA(n_components=2)</span></span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a><span class="co">#X_pca = pca.fit_transform(X_scaled)</span></span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualización PCA</span></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.figure(figsize=(8, 6))</span></span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a><span class="co">#sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette="Set1")</span></span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.title("Visualización PCA (2 componentes)")</span></span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.xlabel("PCA 1")</span></span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.ylabel("PCA 2")</span></span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.show()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Vista general del dataset:
   Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \
0          1          1          1       9500          1          1   
1          1         43          1       9500          1          1   
2          1          1          1       9773          1          1   
3          1         17          2       9254          1          1   
4          1         17          1       9070          1          1   

   Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_27  Feature_28  \
0      132.0          1         19          1  ...           0           8   
1      120.0          1          1          1  ...           0           8   
2      150.0          1         19         38  ...           0           6   
3      141.0          1          1          4  ...           0           6   
4      119.0          1         38         19  ...           0           6   

   Feature_29  Feature_30  Feature_31  Feature_32  Feature_33  Feature_34  \
0           9           8   15.683333           0        11.1         0.6   
1          15           7   11.571429           0        12.7         3.7   
2           6           6   13.666667           0        12.7         3.7   
3           9           4   13.500000           0        16.2         0.3   
4           7           5   11.000000           0        15.5         2.8   

   Feature_35    Target  
0        2.02  Graduate  
1       -1.70  Graduate  
2       -1.70  Graduate  
3       -0.92  Graduate  
4       -4.06   Dropout  

[5 rows x 37 columns]

Forma del dataset: (1600, 37)

Tipos de datos:
Feature_0       int64
Feature_1       int64
Feature_2       int64
Feature_3       int64
Feature_4       int64
Feature_5       int64
Feature_6     float64
Feature_7       int64
Feature_8       int64
Feature_9       int64
Feature_10      int64
Feature_11      int64
Feature_12    float64
Feature_13      int64
Feature_14      int64
Feature_15      int64
Feature_16      int64
Feature_17      int64
Feature_18      int64
Feature_19      int64
Feature_20      int64
Feature_21      int64
Feature_22      int64
Feature_23      int64
Feature_24      int64
Feature_25    float64
Feature_26      int64
Feature_27      int64
Feature_28      int64
Feature_29      int64
Feature_30      int64
Feature_31    float64
Feature_32      int64
Feature_33    float64
Feature_34    float64
Feature_35    float64
Target         object
dtype: object

Valores nulos por columna:
Feature_0     0
Feature_1     0
Feature_2     0
Feature_3     0
Feature_4     0
Feature_5     0
Feature_6     0
Feature_7     0
Feature_8     0
Feature_9     0
Feature_10    0
Feature_11    0
Feature_12    0
Feature_13    0
Feature_14    0
Feature_15    0
Feature_16    0
Feature_17    0
Feature_18    0
Feature_19    0
Feature_20    0
Feature_21    0
Feature_22    0
Feature_23    0
Feature_24    0
Feature_25    0
Feature_26    0
Feature_27    0
Feature_28    0
Feature_29    0
Feature_30    0
Feature_31    0
Feature_32    0
Feature_33    0
Feature_34    0
Feature_35    0
Target        0
dtype: int64

Estadísticas descriptivas:
         Feature_0    Feature_1    Feature_2    Feature_3    Feature_4  \
count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   
mean      1.190625    19.408125     1.710625  8812.920625     0.883125   
std       0.633078    17.496975     1.284199  2154.347497     0.321372   
min       1.000000     1.000000     1.000000    33.000000     0.000000   
25%       1.000000     1.000000     1.000000  9085.000000     1.000000   
50%       1.000000    17.000000     1.000000  9246.000000     1.000000   
75%       1.000000    39.000000     2.000000  9556.000000     1.000000   
max       6.000000    57.000000     6.000000  9991.000000     1.000000   

         Feature_5    Feature_6    Feature_7    Feature_8    Feature_9  ...  \
count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000  ...   
mean      4.630000   132.716187     1.753125    19.847500    22.396875  ...   
std      10.039415    13.407648     6.383780    15.495017    15.310728  ...   
min       1.000000    95.000000     1.000000     1.000000     1.000000  ...   
25%       1.000000   125.000000     1.000000     3.000000     3.000000  ...   
50%       1.000000   133.100000     1.000000    19.000000    19.000000  ...   
75%       1.000000   140.000000     1.000000    37.000000    37.000000  ...   
max      43.000000   190.000000   103.000000    43.000000    44.000000  ...   

        Feature_26   Feature_27   Feature_28  Feature_29   Feature_30  \
count  1600.000000  1600.000000  1600.000000  1600.00000  1600.000000   
mean      0.145625     0.552500     6.198125     7.60625     4.041250   
std       0.728698     1.878017     2.253230     4.24573     3.224096   
min       0.000000     0.000000     0.000000     0.00000     0.000000   
25%       0.000000     0.000000     5.000000     6.00000     0.000000   
50%       0.000000     0.000000     6.000000     8.00000     5.000000   
75%       0.000000     0.000000     7.000000    10.00000     6.000000   
max      12.000000    16.000000    18.000000    27.00000    17.000000   

        Feature_31   Feature_32   Feature_33   Feature_34   Feature_35  
count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000  
mean      9.259147     0.149375    11.592937     1.246875    -0.023500  
std       5.878052     0.754100     2.676223     1.394608     2.257159  
min       0.000000     0.000000     7.600000    -0.800000    -4.060000  
25%       0.000000     0.000000     9.400000     0.300000    -1.700000  
50%      12.000000     0.000000    11.100000     1.400000     0.320000  
75%      13.333333     0.000000    13.900000     2.600000     1.790000  
max      18.571429    12.000000    16.200000     3.700000     3.510000  

[8 rows x 36 columns]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-3-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Distribución de la variable objetivo:
Target
Graduate    800
Dropout     800
Name: count, dtype: int64</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-3-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-3-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-3-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="prueba-quanttile-trasnformer" class="level1">
<h1>PRUEBA QUANTTILE TRASNFORMER</h1>
<div id="cell-5" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> QuantileTransformer</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuración de estilo</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'ggplot'</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">12</span>, <span class="dv">6</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">'Data_fil_results'</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>os.makedirs(output_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar el archivo CSV sin encabezados</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"Data_fil.csv"</span>, header<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Detectar número total de columnas</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>num_columns <span class="op">=</span> df.shape[<span class="dv">1</span>]</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Asignar nombres de columnas dinámicamente</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>feature_columns <span class="op">=</span> [<span class="ss">f'feature_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_columns <span class="op">-</span> <span class="dv">1</span>)]</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>df.columns <span class="op">=</span> feature_columns <span class="op">+</span> [<span class="st">'target'</span>]</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Guardar datos originales</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>df.to_csv(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/original_data.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualización de datos originales (primeras 5 características)</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Visualización de datos originales ==="</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(feature_columns[:<span class="dv">5</span>]):</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">2</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    sns.histplot(df[col], kde<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f'Original: </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/original_distributions.png'</span>)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Aplicación de QuantileTransformer</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[feature_columns]</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>qt <span class="op">=</span> QuantileTransformer(n_quantiles<span class="op">=</span><span class="dv">100</span>, output_distribution<span class="op">=</span><span class="st">'normal'</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>X_trans <span class="op">=</span> qt.fit_transform(X)</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>X_trans_df <span class="op">=</span> pd.DataFrame(X_trans, columns<span class="op">=</span>feature_columns)</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Añadir target y guardar datos transformados</span></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>transformed_df <span class="op">=</span> X_trans_df.copy()</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>transformed_df[<span class="st">'target'</span>] <span class="op">=</span> df[<span class="st">'target'</span>]</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>transformed_df.to_csv(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/transformed_data.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualización de datos transformados (primeras 5 características)</span></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Visualización de datos transformados ==="</span>)</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(feature_columns[:<span class="dv">5</span>]):</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">2</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>    sns.histplot(X_trans_df[col], kde<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f'Transformado: </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/transformed_distributions.png'</span>)</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparación lado a lado (primeras 3 características)</span></span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Comparación antes/después ==="</span>)</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">12</span>))</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(feature_columns[:<span class="dv">3</span>]):</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Original</span></span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">2</span><span class="op">*</span>i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>    sns.histplot(df[col], kde<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f'Original: </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>    plt.ylim(<span class="dv">0</span>, <span class="dv">25</span>)</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transformado</span></span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">2</span><span class="op">*</span>i<span class="op">+</span><span class="dv">2</span>)</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>    sns.histplot(X_trans_df[col], kde<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f'Transformado: </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>    plt.ylim(<span class="dv">0</span>, <span class="dv">25</span>)</span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="ss">f'</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/comparison_distributions.png'</span>)</span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a><span class="co"># Mensaje final</span></span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Resultados guardados en: </span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/"</span>)</span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"- original_data.csv"</span>)</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"- transformed_data.csv"</span>)</span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"- original_distributions.png"</span>)</span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"- transformed_distributions.png"</span>)</span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"- comparison_distributions.png"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
=== Visualización de datos originales ===</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-4-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
=== Visualización de datos transformados ===</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-4-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
=== Comparación antes/después ===</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-4-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Resultados guardados en: Data_fil_results/
- original_data.csv
- transformed_data.csv
- original_distributions.png
- transformed_distributions.png
- comparison_distributions.png</code></pre>
</div>
</div>
</section>
<section id="prueba-2" class="level1">
<h1>PRUEBA 2</h1>
<div id="cell-7" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar el archivo CSV</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"Data_fil_results/transformed_data.csv"</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Separar características y variable objetivo</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">"target"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"target"</span>]</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Escalado de características</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Reducción de dimensionalidad con PCA</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualización de los dos primeros componentes principales</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>X_pca[:, <span class="dv">0</span>], y<span class="op">=</span>X_pca[:, <span class="dv">1</span>], hue<span class="op">=</span>y, palette<span class="op">=</span><span class="st">"Set1"</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Visualización PCA (2 componentes principales)"</span>)</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Componente Principal 1"</span>)</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Componente Principal 2"</span>)</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">"Clase"</span>)</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering con KMeans</span></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> kmeans.fit_predict(X_scaled)</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualización de clusters en el espacio PCA</span></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>X_pca[:, <span class="dv">0</span>], y<span class="op">=</span>X_pca[:, <span class="dv">1</span>], hue<span class="op">=</span>clusters, palette<span class="op">=</span><span class="st">"Set2"</span>)</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Clustering KMeans en espacio PCA"</span>)</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Componente Principal 1"</span>)</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Componente Principal 2"</span>)</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">"Cluster"</span>)</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Boxplots para detección de outliers en algunas variables</span></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>selected_features <span class="op">=</span> X.columns[:<span class="dv">6</span>]  <span class="co"># Puedes ajustar el número de variables</span></span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, feature <span class="kw">in</span> <span class="bu">enumerate</span>(selected_features, <span class="dv">1</span>):</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, i)</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>    sns.boxplot(x<span class="op">=</span>y, y<span class="op">=</span>df[feature])</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"Boxplot de </span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss"> por clase"</span>)</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-5-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-5-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-8" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar el archivo CSV</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"Data_fil_results/transformed_data.csv"</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Mezclar aleatoriamente las filas del DataFrame</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Separar características y variable objetivo</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">"target"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"target"</span>]</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Escalado de características</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Reducción de dimensionalidad con PCA</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualización de los dos primeros componentes principales</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>X_pca[:, <span class="dv">0</span>], y<span class="op">=</span>X_pca[:, <span class="dv">1</span>], hue<span class="op">=</span>y, palette<span class="op">=</span><span class="st">"Set1"</span>)</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Visualización PCA (2 componentes principales)"</span>)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Componente Principal 1"</span>)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Componente Principal 2"</span>)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">"Clase"</span>)</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering con KMeans</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> kmeans.fit_predict(X_scaled)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Agregar los resultados del clustering al DataFrame original</span></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"cluster"</span>] <span class="op">=</span> clusters</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Guardar el nuevo DataFrame con los clusters en un archivo CSV</span></span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>df.to_csv(<span class="st">"clustered_output.csv"</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Archivo 'clustered_output.csv' guardado con éxito."</span>)</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualización de clusters en el espacio PCA</span></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>X_pca[:, <span class="dv">0</span>], y<span class="op">=</span>X_pca[:, <span class="dv">1</span>], hue<span class="op">=</span>clusters, palette<span class="op">=</span><span class="st">"Set2"</span>)</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Clustering KMeans en espacio PCA"</span>)</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Componente Principal 1"</span>)</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Componente Principal 2"</span>)</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">"Cluster"</span>)</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Boxplots para detección de outliers en algunas variables</span></span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>selected_features <span class="op">=</span> X.columns[:<span class="dv">6</span>]  <span class="co"># Puedes ajustar el número de variables</span></span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, feature <span class="kw">in</span> <span class="bu">enumerate</span>(selected_features, <span class="dv">1</span>):</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, i)</span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>    sns.boxplot(x<span class="op">=</span>y, y<span class="op">=</span>df[feature])</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"Boxplot de </span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss"> por clase"</span>)</span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Archivo 'clustered_output.csv' guardado con éxito.</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-6-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-6-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="bloque-1-eda-y-preparacion-de-datos" class="level1">
<h1>BLOQUE 1 EDA Y PREPARACION DE DATOS</h1>
<div id="cell-10" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar el archivo CSV</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"Data_fil_resultstransformed_data.csv"</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Vista general del dataset</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Vista general del dataset:"</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.head())</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Tamaño del dataset</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Tamaño del dataset:"</span>, df.shape)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Tipos de datos</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Tipos de datos:"</span>)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.dtypes)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificación de valores nulos</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Valores nulos por columna:"</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.isnull().<span class="bu">sum</span>())</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Estadísticas descriptivas</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Estadísticas descriptivas:"</span>)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.describe())</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Histograma de las primeras 10 características</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>df.iloc[:, :<span class="dv">10</span>].hist(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>), bins<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Histogramas de las primeras 10 características"</span>)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribución de la variable objetivo</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Distribución de la variable objetivo:"</span>)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[<span class="st">"target"</span>].value_counts())</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span><span class="st">"target"</span>, data<span class="op">=</span>df)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribución de la variable objetivo"</span>)</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Matriz de correlación</span></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> df.drop(<span class="st">"target"</span>, axis<span class="op">=</span><span class="dv">1</span>).corr()</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr_matrix, cmap<span class="op">=</span><span class="st">"coolwarm"</span>, annot<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Matriz de correlación entre características"</span>)</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Vista general del dataset:
   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \
0  -5.199338  -5.199338  -5.199338   0.403108   5.199338  -5.199338   
1  -5.199338   1.275817  -5.199338   0.403108   5.199338  -5.199338   
2  -5.199338  -5.199338  -5.199338   1.073988   5.199338  -5.199338   
3  -5.199338   0.037988   0.666564   0.076032   5.199338  -5.199338   
4  -5.199338   0.037988  -5.199338  -0.908458   5.199338  -5.199338   

   feature_6  feature_7  feature_8  feature_9  ...  feature_27  feature_28  \
0  -0.126937  -5.199338  -0.012660  -5.199338  ...   -5.199338    1.073988   
1  -1.008673  -5.199338  -5.199338  -5.199338  ...   -5.199338    1.073988   
2   1.304923  -5.199338  -0.012660   1.399657  ...   -5.199338    0.000000   
3   0.799083  -5.199338  -5.199338  -0.574460  ...   -5.199338    0.000000   
4  -1.168949  -5.199338   1.508944  -0.216904  ...   -5.199338    0.000000   

   feature_29  feature_30  feature_31  feature_32  feature_33  feature_34  \
0    0.486994    1.399657    2.069575   -5.199338   -0.025322   -0.165327   
1    1.746017    1.029957   -0.198425   -5.199338    0.472789    5.199338   
2   -0.559592    0.559592    0.870846   -5.199338    0.472789    5.199338   
3    0.486994   -0.165327    0.764710   -5.199338    5.199338   -0.682458   
4   -0.216904    0.101452   -0.389414   -5.199338    1.120205    1.073988   

   feature_35    target  
0    1.144237  Graduate  
1   -0.650837  Graduate  
2   -0.650837  Graduate  
3   -0.389414  Graduate  
4   -5.199338   Dropout  

[5 rows x 37 columns]

Tamaño del dataset: (1600, 37)

Tipos de datos:
feature_0     float64
feature_1     float64
feature_2     float64
feature_3     float64
feature_4     float64
feature_5     float64
feature_6     float64
feature_7     float64
feature_8     float64
feature_9     float64
feature_10    float64
feature_11    float64
feature_12    float64
feature_13    float64
feature_14    float64
feature_15    float64
feature_16    float64
feature_17    float64
feature_18    float64
feature_19    float64
feature_20    float64
feature_21    float64
feature_22    float64
feature_23    float64
feature_24    float64
feature_25    float64
feature_26    float64
feature_27    float64
feature_28    float64
feature_29    float64
feature_30    float64
feature_31    float64
feature_32    float64
feature_33    float64
feature_34    float64
feature_35    float64
target         object
dtype: object

Valores nulos por columna:
feature_0     0
feature_1     0
feature_2     0
feature_3     0
feature_4     0
feature_5     0
feature_6     0
feature_7     0
feature_8     0
feature_9     0
feature_10    0
feature_11    0
feature_12    0
feature_13    0
feature_14    0
feature_15    0
feature_16    0
feature_17    0
feature_18    0
feature_19    0
feature_20    0
feature_21    0
feature_22    0
feature_23    0
feature_24    0
feature_25    0
feature_26    0
feature_27    0
feature_28    0
feature_29    0
feature_30    0
feature_31    0
feature_32    0
feature_33    0
feature_34    0
feature_35    0
target        0
dtype: int64

Estadísticas descriptivas:
         feature_0    feature_1    feature_2    feature_3    feature_4  \
count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   
mean     -4.376723    -1.519838    -3.130758     0.207756     3.983992   
std       2.243619     2.832287     3.127375     1.599337     3.341840   
min      -5.199338    -5.199338    -5.199338    -5.199338    -5.199338   
25%      -5.199338    -5.199338    -5.199338    -0.698526     5.199338   
50%      -5.199338     0.037988    -5.199338    -0.012710     5.199338   
75%      -5.199338     0.650837     0.666564     0.666564     5.199338   
max       5.199338     5.199338     5.199338     5.199338     5.199338   

         feature_5    feature_6    feature_7    feature_8    feature_9  ...  \
count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000  ...   
mean     -3.999332    -0.004267    -5.026096    -0.895116    -0.737921  ...   
std       2.577869     1.002694     1.147286     2.428407     2.270125  ...   
min      -5.199338    -5.199338    -5.199338    -5.199338    -5.199338  ...   
25%      -5.199338    -0.650837    -5.199338    -0.530220    -0.698526  ...   
50%      -5.199338     0.114185    -5.199338    -0.012660    -0.216904  ...   
75%      -5.199338     0.650837    -5.199338     0.698526     0.530220  ...   
max       5.199338     5.199338     5.199338     5.199338     5.199338  ...   

        feature_26   feature_27   feature_28   feature_29   feature_30  \
count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   
mean     -4.731779    -4.334720    -0.146120    -0.465676    -1.107644   
std       1.768262     2.281102     1.405877     1.982177     2.620779   
min      -5.199338    -5.199338    -5.199338    -5.199338    -5.199338   
25%      -5.199338    -5.199338    -0.947401    -0.559592    -5.199338   
50%      -5.199338    -5.199338     0.000000     0.139710     0.101452   
75%      -5.199338    -5.199338     0.666564     0.731217     0.559592   
max       5.199338     5.199338     5.199338     5.199338     5.199338   

        feature_31   feature_32   feature_33   feature_34   feature_35  
count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000  
mean     -1.113549    -4.763513    -0.210658    -0.076096    -0.050728  
std       2.612259     1.710076     2.465088     2.478871     2.235828  
min      -5.199338    -5.199338    -5.199338    -5.199338    -5.199338  
25%      -5.199338    -5.199338    -0.619855    -0.682458    -0.650837  
50%      -0.025322    -5.199338    -0.025322     0.191052    -0.114185  
75%       0.666564    -5.199338     0.764710     0.650837     0.764710  
max       5.199338     5.199338     5.199338     5.199338     5.199338  

[8 rows x 36 columns]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-7-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Distribución de la variable objetivo:
target
Graduate    800
Dropout     800
Name: count, dtype: int64</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-7-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-7-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="bloque-2-selección-de-características-con-eda-wrapper" class="level1">
<h1>Bloque 2: Selección de Características con EDA Wrapper</h1>
<div id="cell-12" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar el dataset</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"Data_fil_resultstransformed_data.csv"</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Separar características y variable objetivo</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">"target"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"target"</span>]</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuración</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>num_iterations <span class="op">=</span> <span class="dv">400</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>subset_size_range <span class="op">=</span> (<span class="dv">5</span>, <span class="dv">20</span>)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>feature_counter <span class="op">=</span> Counter()</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Encontrar el mejor subconjunto</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>best_result <span class="op">=</span> results_df.loc[results_df[<span class="st">'accuracy'</span>].idxmax()]</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>best_accuracy <span class="op">=</span> best_result[<span class="st">'accuracy'</span>]</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>best_features <span class="op">=</span> best_result[<span class="st">'features'</span>]</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Búsqueda estocástica</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_iterations):</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>    subset_size <span class="op">=</span> random.randint(<span class="op">*</span>subset_size_range)</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>    selected_features <span class="op">=</span> random.sample(<span class="bu">list</span>(X.columns), subset_size)</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>    X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>        X[selected_features], y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>    clf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>    clf.fit(X_train, y_train)</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>    results.append({</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">"iteration"</span>: i <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">"accuracy"</span>: acc,</span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">"subset_size"</span>: subset_size,</span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">"features"</span>: selected_features</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>    feature_counter.update(selected_features)</span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Convertir resultados a DataFrame</span></span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Evolución del Accuracy</span></span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>sns.lineplot(x<span class="op">=</span><span class="st">"iteration"</span>, y<span class="op">=</span><span class="st">"accuracy"</span>, data<span class="op">=</span>results_df, marker<span class="op">=</span><span class="st">"o"</span>)</span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Evolución del Accuracy por Iteración"</span>)</span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Iteración"</span>)</span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Accuracy"</span>)</span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Distribución del Tamaño de Subconjuntos</span></span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a>sns.histplot(results_df[<span class="st">"subset_size"</span>], bins<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribución del Tamaño de Subconjuntos Evaluados"</span>)</span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Tamaño del Subconjunto"</span>)</span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frecuencia"</span>)</span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Tabla de los Mejores Subconjuntos</span></span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a>top_results <span class="op">=</span> results_df.sort_values(by<span class="op">=</span><span class="st">"accuracy"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">5</span>)</span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top 5 subconjuntos con mayor accuracy:"</span>)</span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_results[[<span class="st">"iteration"</span>, <span class="st">"accuracy"</span>, <span class="st">"subset_size"</span>, <span class="st">"features"</span>]])</span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Frecuencia de Selección de Características</span></span>
<span id="cb17-82"><a href="#cb17-82" aria-hidden="true" tabindex="-1"></a>freq_df <span class="op">=</span> pd.DataFrame.from_dict(feature_counter, orient<span class="op">=</span><span class="st">'index'</span>, columns<span class="op">=</span>[<span class="st">"frequency"</span>])</span>
<span id="cb17-83"><a href="#cb17-83" aria-hidden="true" tabindex="-1"></a>freq_df <span class="op">=</span> freq_df.sort_values(by<span class="op">=</span><span class="st">"frequency"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-84"><a href="#cb17-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-85"><a href="#cb17-85" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb17-86"><a href="#cb17-86" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>freq_df.index, y<span class="op">=</span><span class="st">"frequency"</span>, data<span class="op">=</span>freq_df)</span>
<span id="cb17-87"><a href="#cb17-87" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb17-88"><a href="#cb17-88" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Frecuencia de Selección de Características"</span>)</span>
<span id="cb17-89"><a href="#cb17-89" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Características"</span>)</span>
<span id="cb17-90"><a href="#cb17-90" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frecuencia"</span>)</span>
<span id="cb17-91"><a href="#cb17-91" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb17-92"><a href="#cb17-92" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-93"><a href="#cb17-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-94"><a href="#cb17-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-95"><a href="#cb17-95" aria-hidden="true" tabindex="-1"></a><span class="co"># Al final del Bloque 2, después de calcular los resultados</span></span>
<span id="cb17-96"><a href="#cb17-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-97"><a href="#cb17-97" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Mostrar el mejor subconjunto de características</span></span>
<span id="cb17-98"><a href="#cb17-98" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Mejor subconjunto de características ==="</span>)</span>
<span id="cb17-99"><a href="#cb17-99" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>best_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-100"><a href="#cb17-100" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Características seleccionadas:"</span>)</span>
<span id="cb17-101"><a href="#cb17-101" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_features)</span>
<span id="cb17-102"><a href="#cb17-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-103"><a href="#cb17-103" aria-hidden="true" tabindex="-1"></a><span class="co"># También como tabla</span></span>
<span id="cb17-104"><a href="#cb17-104" aria-hidden="true" tabindex="-1"></a>best_features_df <span class="op">=</span> pd.DataFrame(best_features, columns<span class="op">=</span>[<span class="st">"feature"</span>])</span>
<span id="cb17-105"><a href="#cb17-105" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Tabla de características seleccionadas por el mejor individuo:"</span>)</span>
<span id="cb17-106"><a href="#cb17-106" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_features_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-8-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 5 subconjuntos con mayor accuracy:
     iteration  accuracy  subset_size  \
68          69  0.904167           19   
152        153  0.900000           20   
372        373  0.897917           17   
276        277  0.895833           17   
271        272  0.893750           12   

                                              features  
68   [feature_33, feature_29, feature_16, feature_3...  
152  [feature_2, feature_33, feature_23, feature_34...  
372  [feature_2, feature_23, feature_15, feature_16...  
276  [feature_14, feature_12, feature_28, feature_1...  
271  [feature_29, feature_33, feature_28, feature_3...  </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-8-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
=== Mejor subconjunto de características ===
Accuracy: 0.8896
Características seleccionadas:
['feature_16', np.str_('feature_30'), np.str_('feature_18'), 'feature_14', np.str_('feature_3'), np.str_('feature_23')]

Tabla de características seleccionadas por el mejor individuo:
      feature
0  feature_16
1  feature_30
2  feature_18
3  feature_14
4   feature_3
5  feature_23</code></pre>
</div>
</div>
</section>
<section id="pruebas-bloque-2" class="level1">
<h1>PRUEBAS BLOQUE 2</h1>
<div id="cell-14" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, ExtraTreesClassifier</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.discriminant_analysis <span class="im">import</span> QuadraticDiscriminantAnalysis</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, f1_score</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="co"># === CONFIGURACIÓN DEL EXPERIMENTO ===</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> {</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">"experiment_id"</span>: <span class="dv">6</span>,</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"num_generations"</span>: <span class="dv">50</span>,</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"population_size"</span>: <span class="dv">20</span>,</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">"subset_size_range"</span>: (<span class="dv">5</span>, <span class="dv">10</span>),</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">"elite_fraction"</span>: <span class="fl">0.2</span>,</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">"mutation_rate"</span>: <span class="fl">0.3</span>,</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classifier_name"</span>: <span class="st">"SVM"</span>,  <span class="co"># Cambiar a: "SVM", "KNN", etc.</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">"random_state"</span>: <span class="dv">42</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a><span class="co"># === CARGA DE DATOS ===</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>data_file <span class="op">=</span> <span class="st">"Data_fil_resultstransformed_data.csv"</span></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(data_file):</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">FileNotFoundError</span>(<span class="ss">f"El archivo </span><span class="sc">{</span>data_file<span class="sc">}</span><span class="ss"> no se encuentra en el directorio actual."</span>)</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(data_file)</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">"target"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"target"</span>]</span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> <span class="bu">list</span>(X.columns)</span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a><span class="co"># === FUNCIÓN PARA OBTENER CLASIFICADOR ===</span></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_classifier(name, seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name <span class="op">==</span> <span class="st">"RandomForest"</span>:</span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"SVM"</span>:</span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, probability<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"LogisticRegression"</span>:</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"KNN"</span>:</span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">7</span>)</span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"DecisionTree"</span>:</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> DecisionTreeClassifier(random_state<span class="op">=</span>seed)</span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"ExtraTrees"</span>:</span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ExtraTreesClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"NaiveBayes"</span>:</span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> GaussianNB()</span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"MLP"</span>:</span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> MLPClassifier(hidden_layer_sizes<span class="op">=</span>(<span class="dv">100</span>,), max_iter<span class="op">=</span><span class="dv">500</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"QDA"</span>:</span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> QuadraticDiscriminantAnalysis()</span>
<span id="cb20-62"><a href="#cb20-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb20-63"><a href="#cb20-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Clasificador no reconocido"</span>)</span>
<span id="cb20-64"><a href="#cb20-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-65"><a href="#cb20-65" aria-hidden="true" tabindex="-1"></a><span class="co"># === FUNCIONES AUXILIARES ===</span></span>
<span id="cb20-66"><a href="#cb20-66" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_subset(features, classifier):</span>
<span id="cb20-67"><a href="#cb20-67" aria-hidden="true" tabindex="-1"></a>    X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb20-68"><a href="#cb20-68" aria-hidden="true" tabindex="-1"></a>        X[features], y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span>config[<span class="st">"random_state"</span>]</span>
<span id="cb20-69"><a href="#cb20-69" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb20-70"><a href="#cb20-70" aria-hidden="true" tabindex="-1"></a>    classifier.fit(X_train, y_train)</span>
<span id="cb20-71"><a href="#cb20-71" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> classifier.predict(X_test)</span>
<span id="cb20-72"><a href="#cb20-72" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb20-73"><a href="#cb20-73" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> f1_score(y_test, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb20-74"><a href="#cb20-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> acc, f1</span>
<span id="cb20-75"><a href="#cb20-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-76"><a href="#cb20-76" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_population(prob_dist, size):</span>
<span id="cb20-77"><a href="#cb20-77" aria-hidden="true" tabindex="-1"></a>    population <span class="op">=</span> []</span>
<span id="cb20-78"><a href="#cb20-78" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(size):</span>
<span id="cb20-79"><a href="#cb20-79" aria-hidden="true" tabindex="-1"></a>        subset_size <span class="op">=</span> random.randint(<span class="op">*</span>config[<span class="st">"subset_size_range"</span>])</span>
<span id="cb20-80"><a href="#cb20-80" aria-hidden="true" tabindex="-1"></a>        selected <span class="op">=</span> np.random.choice(feature_names, size<span class="op">=</span>subset_size, replace<span class="op">=</span><span class="va">False</span>, p<span class="op">=</span>prob_dist)</span>
<span id="cb20-81"><a href="#cb20-81" aria-hidden="true" tabindex="-1"></a>        population.append(<span class="bu">list</span>(selected))</span>
<span id="cb20-82"><a href="#cb20-82" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> population</span>
<span id="cb20-83"><a href="#cb20-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-84"><a href="#cb20-84" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mutate(subset):</span>
<span id="cb20-85"><a href="#cb20-85" aria-hidden="true" tabindex="-1"></a>    mutated <span class="op">=</span> subset.copy()</span>
<span id="cb20-86"><a href="#cb20-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> random.random() <span class="op">&lt;</span> config[<span class="st">"mutation_rate"</span>]:</span>
<span id="cb20-87"><a href="#cb20-87" aria-hidden="true" tabindex="-1"></a>        idx_to_replace <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="bu">len</span>(mutated)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb20-88"><a href="#cb20-88" aria-hidden="true" tabindex="-1"></a>        new_feature <span class="op">=</span> random.choice([f <span class="cf">for</span> f <span class="kw">in</span> feature_names <span class="cf">if</span> f <span class="kw">not</span> <span class="kw">in</span> mutated])</span>
<span id="cb20-89"><a href="#cb20-89" aria-hidden="true" tabindex="-1"></a>        mutated[idx_to_replace] <span class="op">=</span> new_feature</span>
<span id="cb20-90"><a href="#cb20-90" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mutated</span>
<span id="cb20-91"><a href="#cb20-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-92"><a href="#cb20-92" aria-hidden="true" tabindex="-1"></a><span class="co"># === INICIALIZACIÓN ===</span></span>
<span id="cb20-93"><a href="#cb20-93" aria-hidden="true" tabindex="-1"></a>initial_prob <span class="op">=</span> np.ones(<span class="bu">len</span>(feature_names)) <span class="op">/</span> <span class="bu">len</span>(feature_names)</span>
<span id="cb20-94"><a href="#cb20-94" aria-hidden="true" tabindex="-1"></a>population <span class="op">=</span> generate_population(initial_prob, config[<span class="st">"population_size"</span>])</span>
<span id="cb20-95"><a href="#cb20-95" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb20-96"><a href="#cb20-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-97"><a href="#cb20-97" aria-hidden="true" tabindex="-1"></a><span class="co"># === EVOLUCIÓN POR GENERACIONES ===</span></span>
<span id="cb20-98"><a href="#cb20-98" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> gen <span class="kw">in</span> <span class="bu">range</span>(config[<span class="st">"num_generations"</span>]):</span>
<span id="cb20-99"><a href="#cb20-99" aria-hidden="true" tabindex="-1"></a>    gen_results <span class="op">=</span> []</span>
<span id="cb20-100"><a href="#cb20-100" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> subset <span class="kw">in</span> population:</span>
<span id="cb20-101"><a href="#cb20-101" aria-hidden="true" tabindex="-1"></a>        acc_nb, _ <span class="op">=</span> evaluate_subset(subset, GaussianNB())</span>
<span id="cb20-102"><a href="#cb20-102" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> acc_nb <span class="op">&lt;</span> <span class="fl">0.5</span>:</span>
<span id="cb20-103"><a href="#cb20-103" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span>  <span class="co"># Filtro rápido</span></span>
<span id="cb20-104"><a href="#cb20-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-105"><a href="#cb20-105" aria-hidden="true" tabindex="-1"></a>        clf <span class="op">=</span> get_classifier(config[<span class="st">"classifier_name"</span>], config[<span class="st">"random_state"</span>])</span>
<span id="cb20-106"><a href="#cb20-106" aria-hidden="true" tabindex="-1"></a>        acc_rf, f1_rf <span class="op">=</span> evaluate_subset(subset, clf)</span>
<span id="cb20-107"><a href="#cb20-107" aria-hidden="true" tabindex="-1"></a>        gen_results.append({</span>
<span id="cb20-108"><a href="#cb20-108" aria-hidden="true" tabindex="-1"></a>            <span class="st">"experiment_id"</span>: config[<span class="st">"experiment_id"</span>],</span>
<span id="cb20-109"><a href="#cb20-109" aria-hidden="true" tabindex="-1"></a>            <span class="st">"generation"</span>: gen <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb20-110"><a href="#cb20-110" aria-hidden="true" tabindex="-1"></a>            <span class="st">"features"</span>: subset,</span>
<span id="cb20-111"><a href="#cb20-111" aria-hidden="true" tabindex="-1"></a>            <span class="st">"accuracy"</span>: acc_rf,</span>
<span id="cb20-112"><a href="#cb20-112" aria-hidden="true" tabindex="-1"></a>            <span class="st">"f1_score"</span>: f1_rf,</span>
<span id="cb20-113"><a href="#cb20-113" aria-hidden="true" tabindex="-1"></a>            <span class="st">"subset_size"</span>: <span class="bu">len</span>(subset),</span>
<span id="cb20-114"><a href="#cb20-114" aria-hidden="true" tabindex="-1"></a>            <span class="st">"classifier"</span>: config[<span class="st">"classifier_name"</span>]</span>
<span id="cb20-115"><a href="#cb20-115" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb20-116"><a href="#cb20-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-117"><a href="#cb20-117" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Selección elitista</span></span>
<span id="cb20-118"><a href="#cb20-118" aria-hidden="true" tabindex="-1"></a>    gen_results.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">"accuracy"</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-119"><a href="#cb20-119" aria-hidden="true" tabindex="-1"></a>    elite_count <span class="op">=</span> <span class="bu">max</span>(<span class="dv">1</span>, <span class="bu">int</span>(config[<span class="st">"elite_fraction"</span>] <span class="op">*</span> <span class="bu">len</span>(gen_results)))</span>
<span id="cb20-120"><a href="#cb20-120" aria-hidden="true" tabindex="-1"></a>    elites <span class="op">=</span> gen_results[:elite_count]</span>
<span id="cb20-121"><a href="#cb20-121" aria-hidden="true" tabindex="-1"></a>    results.extend(elites)</span>
<span id="cb20-122"><a href="#cb20-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-123"><a href="#cb20-123" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Modelar distribución de características</span></span>
<span id="cb20-124"><a href="#cb20-124" aria-hidden="true" tabindex="-1"></a>    feature_counter <span class="op">=</span> Counter()</span>
<span id="cb20-125"><a href="#cb20-125" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> elite <span class="kw">in</span> elites:</span>
<span id="cb20-126"><a href="#cb20-126" aria-hidden="true" tabindex="-1"></a>        feature_counter.update(elite[<span class="st">"features"</span>])</span>
<span id="cb20-127"><a href="#cb20-127" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="bu">sum</span>(feature_counter.values())</span>
<span id="cb20-128"><a href="#cb20-128" aria-hidden="true" tabindex="-1"></a>    prob_dist <span class="op">=</span> np.array([feature_counter.get(f, <span class="dv">0</span>) <span class="op">/</span> total <span class="cf">for</span> f <span class="kw">in</span> feature_names])</span>
<span id="cb20-129"><a href="#cb20-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-130"><a href="#cb20-130" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generar nueva población con mutación</span></span>
<span id="cb20-131"><a href="#cb20-131" aria-hidden="true" tabindex="-1"></a>    new_population <span class="op">=</span> []</span>
<span id="cb20-132"><a href="#cb20-132" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(new_population) <span class="op">&lt;</span> config[<span class="st">"population_size"</span>]:</span>
<span id="cb20-133"><a href="#cb20-133" aria-hidden="true" tabindex="-1"></a>        base_subset <span class="op">=</span> random.choice(elites)[<span class="st">"features"</span>]</span>
<span id="cb20-134"><a href="#cb20-134" aria-hidden="true" tabindex="-1"></a>        mutated_subset <span class="op">=</span> mutate(base_subset)</span>
<span id="cb20-135"><a href="#cb20-135" aria-hidden="true" tabindex="-1"></a>        new_population.append(mutated_subset)</span>
<span id="cb20-136"><a href="#cb20-136" aria-hidden="true" tabindex="-1"></a>    population <span class="op">=</span> new_population</span>
<span id="cb20-137"><a href="#cb20-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-138"><a href="#cb20-138" aria-hidden="true" tabindex="-1"></a><span class="co"># === RESULTADOS ===</span></span>
<span id="cb20-139"><a href="#cb20-139" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb20-140"><a href="#cb20-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-141"><a href="#cb20-141" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Evolución del Accuracy</span></span>
<span id="cb20-142"><a href="#cb20-142" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb20-143"><a href="#cb20-143" aria-hidden="true" tabindex="-1"></a>sns.lineplot(x<span class="op">=</span><span class="st">"generation"</span>, y<span class="op">=</span><span class="st">"accuracy"</span>, data<span class="op">=</span>results_df, marker<span class="op">=</span><span class="st">"o"</span>)</span>
<span id="cb20-144"><a href="#cb20-144" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Evolución del Accuracy - Clasificador: </span><span class="sc">{</span>config[<span class="st">'classifier_name'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-145"><a href="#cb20-145" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Generación"</span>)</span>
<span id="cb20-146"><a href="#cb20-146" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Accuracy"</span>)</span>
<span id="cb20-147"><a href="#cb20-147" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb20-148"><a href="#cb20-148" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb20-149"><a href="#cb20-149" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb20-150"><a href="#cb20-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-151"><a href="#cb20-151" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Distribución del Tamaño de Subconjuntos</span></span>
<span id="cb20-152"><a href="#cb20-152" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb20-153"><a href="#cb20-153" aria-hidden="true" tabindex="-1"></a>sns.histplot(results_df[<span class="st">"subset_size"</span>], bins<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb20-154"><a href="#cb20-154" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribución del Tamaño de Subconjuntos Evaluados"</span>)</span>
<span id="cb20-155"><a href="#cb20-155" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Tamaño del Subconjunto"</span>)</span>
<span id="cb20-156"><a href="#cb20-156" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frecuencia"</span>)</span>
<span id="cb20-157"><a href="#cb20-157" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb20-158"><a href="#cb20-158" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb20-159"><a href="#cb20-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-160"><a href="#cb20-160" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Tabla de los Mejores Subconjuntos</span></span>
<span id="cb20-161"><a href="#cb20-161" aria-hidden="true" tabindex="-1"></a>top_results <span class="op">=</span> results_df.sort_values(by<span class="op">=</span><span class="st">"accuracy"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">5</span>)</span>
<span id="cb20-162"><a href="#cb20-162" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"🔝 Top 5 subconjuntos con mayor accuracy:"</span>)</span>
<span id="cb20-163"><a href="#cb20-163" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_results[[<span class="st">"generation"</span>, <span class="st">"accuracy"</span>, <span class="st">"f1_score"</span>, <span class="st">"subset_size"</span>, <span class="st">"features"</span>]])</span>
<span id="cb20-164"><a href="#cb20-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-165"><a href="#cb20-165" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Frecuencia de Selección de Características</span></span>
<span id="cb20-166"><a href="#cb20-166" aria-hidden="true" tabindex="-1"></a>feature_counter <span class="op">=</span> Counter()</span>
<span id="cb20-167"><a href="#cb20-167" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> results_df[<span class="st">"features"</span>]:</span>
<span id="cb20-168"><a href="#cb20-168" aria-hidden="true" tabindex="-1"></a>    feature_counter.update(row)</span>
<span id="cb20-169"><a href="#cb20-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-170"><a href="#cb20-170" aria-hidden="true" tabindex="-1"></a>freq_df <span class="op">=</span> pd.DataFrame.from_dict(feature_counter, orient<span class="op">=</span><span class="st">'index'</span>, columns<span class="op">=</span>[<span class="st">"frequency"</span>])</span>
<span id="cb20-171"><a href="#cb20-171" aria-hidden="true" tabindex="-1"></a>freq_df <span class="op">=</span> freq_df.sort_values(by<span class="op">=</span><span class="st">"frequency"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb20-172"><a href="#cb20-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-173"><a href="#cb20-173" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb20-174"><a href="#cb20-174" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>freq_df.index, y<span class="op">=</span><span class="st">"frequency"</span>, data<span class="op">=</span>freq_df)</span>
<span id="cb20-175"><a href="#cb20-175" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb20-176"><a href="#cb20-176" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Frecuencia de Selección de Características"</span>)</span>
<span id="cb20-177"><a href="#cb20-177" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Características"</span>)</span>
<span id="cb20-178"><a href="#cb20-178" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frecuencia"</span>)</span>
<span id="cb20-179"><a href="#cb20-179" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb20-180"><a href="#cb20-180" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb20-181"><a href="#cb20-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-182"><a href="#cb20-182" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Mejor subconjunto</span></span>
<span id="cb20-183"><a href="#cb20-183" aria-hidden="true" tabindex="-1"></a>best_result <span class="op">=</span> results_df.loc[results_df[<span class="st">'accuracy'</span>].idxmax()]</span>
<span id="cb20-184"><a href="#cb20-184" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">✅ Mejor subconjunto de características:"</span>)</span>
<span id="cb20-185"><a href="#cb20-185" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>best_result[<span class="st">'accuracy'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb20-186"><a href="#cb20-186" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Características seleccionadas:"</span>)</span>
<span id="cb20-187"><a href="#cb20-187" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_result[<span class="st">'features'</span>])</span>
<span id="cb20-188"><a href="#cb20-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-189"><a href="#cb20-189" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Tabla de resultados acumulados</span></span>
<span id="cb20-190"><a href="#cb20-190" aria-hidden="true" tabindex="-1"></a>summary <span class="op">=</span> results_df.groupby(<span class="st">"experiment_id"</span>).agg({</span>
<span id="cb20-191"><a href="#cb20-191" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classifier"</span>: <span class="st">"first"</span>,</span>
<span id="cb20-192"><a href="#cb20-192" aria-hidden="true" tabindex="-1"></a>    <span class="st">"accuracy"</span>: [<span class="st">"max"</span>, <span class="st">"mean"</span>],</span>
<span id="cb20-193"><a href="#cb20-193" aria-hidden="true" tabindex="-1"></a>    <span class="st">"f1_score"</span>: <span class="st">"mean"</span>,</span>
<span id="cb20-194"><a href="#cb20-194" aria-hidden="true" tabindex="-1"></a>    <span class="st">"subset_size"</span>: <span class="st">"mean"</span>,</span>
<span id="cb20-195"><a href="#cb20-195" aria-hidden="true" tabindex="-1"></a>    <span class="st">"generation"</span>: <span class="st">"count"</span></span>
<span id="cb20-196"><a href="#cb20-196" aria-hidden="true" tabindex="-1"></a>}).reset_index()</span>
<span id="cb20-197"><a href="#cb20-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-198"><a href="#cb20-198" aria-hidden="true" tabindex="-1"></a>summary.columns <span class="op">=</span> [</span>
<span id="cb20-199"><a href="#cb20-199" aria-hidden="true" tabindex="-1"></a>    <span class="st">"experiment_id"</span>, <span class="st">"classifier"</span>, <span class="st">"max_accuracy"</span>, <span class="st">"mean_accuracy"</span>,</span>
<span id="cb20-200"><a href="#cb20-200" aria-hidden="true" tabindex="-1"></a>    <span class="st">"mean_f1_score"</span>, <span class="st">"mean_subset_size"</span>, <span class="st">"total_generations"</span></span>
<span id="cb20-201"><a href="#cb20-201" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb20-202"><a href="#cb20-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-203"><a href="#cb20-203" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Tabla de resultados acumulados:"</span>)</span>
<span id="cb20-204"><a href="#cb20-204" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-9-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>🔝 Top 5 subconjuntos con mayor accuracy:
      generation  accuracy  f1_score  subset_size  \
1183         296  0.897917  0.897883            5   
1182         296  0.897917  0.897883            5   
1181         296  0.897917  0.897883            5   
1180         296  0.897917  0.897883            5   
1179         295  0.897917  0.897883            5   

                                               features  
1183  [feature_30, feature_28, feature_16, feature_3...  
1182  [feature_30, feature_28, feature_16, feature_3...  
1181  [feature_30, feature_28, feature_16, feature_3...  
1180  [feature_30, feature_28, feature_16, feature_3...  
1179  [feature_30, feature_28, feature_16, feature_3...  </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-9-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
✅ Mejor subconjunto de características:
Accuracy: 0.8979
Características seleccionadas:
[np.str_('feature_30'), np.str_('feature_28'), 'feature_16', 'feature_3', 'feature_20']

📊 Tabla de resultados acumulados:
   experiment_id    classifier  max_accuracy  mean_accuracy  mean_f1_score  \
0              6  DecisionTree      0.897917       0.896925       0.896887   

   mean_subset_size  total_generations  
0             5.005               1200  </code></pre>
</div>
</div>
</section>
<section id="prueba-3" class="level1">
<h1>PRUEBA 3</h1>
<div id="cell-16" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, ExtraTreesClassifier</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.discriminant_analysis <span class="im">import</span> QuadraticDiscriminantAnalysis</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, f1_score</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="co"># === CONFIGURACIÓN GENERAL ===</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>results_log_file <span class="op">=</span> <span class="st">"results_log.csv"</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Auto-incrementar experiment_id</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> os.path.exists(results_log_file):</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>    existing_df <span class="op">=</span> pd.read_csv(results_log_file)</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>    last_id <span class="op">=</span> existing_df[<span class="st">"experiment_id"</span>].<span class="bu">max</span>()</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>    experiment_id <span class="op">=</span> last_id <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>    experiment_id <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> {</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>    <span class="st">"experiment_id"</span>: experiment_id,</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">"num_generations"</span>: <span class="dv">600</span>,</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">"population_size"</span>: <span class="dv">20</span>,</span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">"subset_size_range"</span>: (<span class="dv">5</span>, <span class="dv">10</span>),</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>    <span class="st">"elite_fraction"</span>: <span class="fl">0.2</span>,</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>    <span class="st">"mutation_rate"</span>: <span class="fl">0.3</span>,</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classifier_name"</span>: <span class="st">"DecisionTree"</span>,  <span class="co"># Cambiar a: "SVM", "KNN", etc.</span></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>    <span class="st">"random_state"</span>: <span class="dv">42</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a><span class="co"># === CARGA DE DATOS ===</span></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>data_file <span class="op">=</span> <span class="st">"Data_fil_resultstransformed_data.csv"</span></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(data_file):</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">FileNotFoundError</span>(<span class="ss">f"El archivo </span><span class="sc">{</span>data_file<span class="sc">}</span><span class="ss"> no se encuentra en el directorio actual."</span>)</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(data_file)</span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">"target"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"target"</span>]</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> <span class="bu">list</span>(X.columns)</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a><span class="co"># === FUNCIÓN PARA OBTENER CLASIFICADOR ===</span></span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_classifier(name, seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name <span class="op">==</span> <span class="st">"RandomForest"</span>:</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"SVM"</span>:</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, probability<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"LogisticRegression"</span>:</span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"KNN"</span>:</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">7</span>)</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"DecisionTree"</span>:</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> DecisionTreeClassifier(random_state<span class="op">=</span>seed)</span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"ExtraTrees"</span>:</span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ExtraTreesClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"NaiveBayes"</span>:</span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> GaussianNB()</span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"MLP"</span>:</span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> MLPClassifier(hidden_layer_sizes<span class="op">=</span>(<span class="dv">100</span>,), max_iter<span class="op">=</span><span class="dv">500</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"QDA"</span>:</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> QuadraticDiscriminantAnalysis()</span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Clasificador no reconocido"</span>)</span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a><span class="co"># === FUNCIONES AUXILIARES ===</span></span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_subset(features, classifier):</span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>    X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a>        X[features], y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span>config[<span class="st">"random_state"</span>]</span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a>    classifier.fit(X_train, y_train)</span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> classifier.predict(X_test)</span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> f1_score(y_test, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> acc, f1</span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_population(prob_dist, size):</span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a>    population <span class="op">=</span> []</span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(size):</span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a>        subset_size <span class="op">=</span> random.randint(<span class="op">*</span>config[<span class="st">"subset_size_range"</span>])</span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a>        selected <span class="op">=</span> np.random.choice(feature_names, size<span class="op">=</span>subset_size, replace<span class="op">=</span><span class="va">False</span>, p<span class="op">=</span>prob_dist)</span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a>        population.append(<span class="bu">list</span>(selected))</span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> population</span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mutate(subset):</span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a>    mutated <span class="op">=</span> subset.copy()</span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> random.random() <span class="op">&lt;</span> config[<span class="st">"mutation_rate"</span>]:</span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a>        idx_to_replace <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="bu">len</span>(mutated)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb23-98"><a href="#cb23-98" aria-hidden="true" tabindex="-1"></a>        new_feature <span class="op">=</span> random.choice([f <span class="cf">for</span> f <span class="kw">in</span> feature_names <span class="cf">if</span> f <span class="kw">not</span> <span class="kw">in</span> mutated])</span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a>        mutated[idx_to_replace] <span class="op">=</span> new_feature</span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mutated</span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a><span class="co"># === INICIALIZACIÓN ===</span></span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a>initial_prob <span class="op">=</span> np.ones(<span class="bu">len</span>(feature_names)) <span class="op">/</span> <span class="bu">len</span>(feature_names)</span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a>population <span class="op">=</span> generate_population(initial_prob, config[<span class="st">"population_size"</span>])</span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a><span class="co"># === EVOLUCIÓN POR GENERACIONES (con GRAPeR) ===</span></span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> gen <span class="kw">in</span> <span class="bu">range</span>(config[<span class="st">"num_generations"</span>]):</span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a>    gen_results <span class="op">=</span> []</span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> subset <span class="kw">in</span> population:</span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a>        acc_nb, _ <span class="op">=</span> evaluate_subset(subset, GaussianNB())</span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> acc_nb <span class="op">&lt;</span> <span class="fl">0.5</span>:</span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span>  <span class="co"># Filtro rápido con Naive Bayes</span></span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a>        clf <span class="op">=</span> get_classifier(config[<span class="st">"classifier_name"</span>], config[<span class="st">"random_state"</span>])</span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a>        acc_rf, f1_rf <span class="op">=</span> evaluate_subset(subset, clf)</span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a>        gen_results.append({</span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a>            <span class="st">"experiment_id"</span>: config[<span class="st">"experiment_id"</span>],</span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a>            <span class="st">"generation"</span>: gen <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb23-120"><a href="#cb23-120" aria-hidden="true" tabindex="-1"></a>            <span class="st">"features"</span>: subset,</span>
<span id="cb23-121"><a href="#cb23-121" aria-hidden="true" tabindex="-1"></a>            <span class="st">"accuracy"</span>: acc_rf,</span>
<span id="cb23-122"><a href="#cb23-122" aria-hidden="true" tabindex="-1"></a>            <span class="st">"f1_score"</span>: f1_rf,</span>
<span id="cb23-123"><a href="#cb23-123" aria-hidden="true" tabindex="-1"></a>            <span class="st">"subset_size"</span>: <span class="bu">len</span>(subset),</span>
<span id="cb23-124"><a href="#cb23-124" aria-hidden="true" tabindex="-1"></a>            <span class="st">"classifier"</span>: config[<span class="st">"classifier_name"</span>]</span>
<span id="cb23-125"><a href="#cb23-125" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb23-126"><a href="#cb23-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-127"><a href="#cb23-127" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> gen_results:</span>
<span id="cb23-128"><a href="#cb23-128" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb23-129"><a href="#cb23-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-130"><a href="#cb23-130" aria-hidden="true" tabindex="-1"></a>    <span class="co"># === GRAPeR: distribución probabilística por ranking ===</span></span>
<span id="cb23-131"><a href="#cb23-131" aria-hidden="true" tabindex="-1"></a>    gen_results.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">"accuracy"</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-132"><a href="#cb23-132" aria-hidden="true" tabindex="-1"></a>    rank_weights <span class="op">=</span> np.linspace(<span class="fl">1.0</span>, <span class="fl">0.1</span>, <span class="bu">len</span>(gen_results))  <span class="co"># Mayor peso a mejor ranking</span></span>
<span id="cb23-133"><a href="#cb23-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-134"><a href="#cb23-134" aria-hidden="true" tabindex="-1"></a>    feature_counter <span class="op">=</span> Counter()</span>
<span id="cb23-135"><a href="#cb23-135" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, res <span class="kw">in</span> <span class="bu">enumerate</span>(gen_results):</span>
<span id="cb23-136"><a href="#cb23-136" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> rank_weights[idx]</span>
<span id="cb23-137"><a href="#cb23-137" aria-hidden="true" tabindex="-1"></a>        feature_counter.update({f: weight <span class="cf">for</span> f <span class="kw">in</span> res[<span class="st">"features"</span>]})</span>
<span id="cb23-138"><a href="#cb23-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-139"><a href="#cb23-139" aria-hidden="true" tabindex="-1"></a>    total_weight <span class="op">=</span> <span class="bu">sum</span>(feature_counter.values())</span>
<span id="cb23-140"><a href="#cb23-140" aria-hidden="true" tabindex="-1"></a>    prob_dist <span class="op">=</span> np.array([feature_counter.get(f, <span class="dv">0</span>) <span class="op">/</span> total_weight <span class="cf">for</span> f <span class="kw">in</span> feature_names])</span>
<span id="cb23-141"><a href="#cb23-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-142"><a href="#cb23-142" aria-hidden="true" tabindex="-1"></a>    <span class="co"># === Elitismo: guardar top resultados de esta generación ===</span></span>
<span id="cb23-143"><a href="#cb23-143" aria-hidden="true" tabindex="-1"></a>    elite_count <span class="op">=</span> <span class="bu">max</span>(<span class="dv">1</span>, <span class="bu">int</span>(config[<span class="st">"elite_fraction"</span>] <span class="op">*</span> <span class="bu">len</span>(gen_results)))</span>
<span id="cb23-144"><a href="#cb23-144" aria-hidden="true" tabindex="-1"></a>    elites <span class="op">=</span> gen_results[:elite_count]</span>
<span id="cb23-145"><a href="#cb23-145" aria-hidden="true" tabindex="-1"></a>    results.extend(elites)</span>
<span id="cb23-146"><a href="#cb23-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-147"><a href="#cb23-147" aria-hidden="true" tabindex="-1"></a>    <span class="co"># === Generar nueva población con mutación ===</span></span>
<span id="cb23-148"><a href="#cb23-148" aria-hidden="true" tabindex="-1"></a>    new_population <span class="op">=</span> []</span>
<span id="cb23-149"><a href="#cb23-149" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(new_population) <span class="op">&lt;</span> config[<span class="st">"population_size"</span>]:</span>
<span id="cb23-150"><a href="#cb23-150" aria-hidden="true" tabindex="-1"></a>        base_subset <span class="op">=</span> random.choice(elites)[<span class="st">"features"</span>]</span>
<span id="cb23-151"><a href="#cb23-151" aria-hidden="true" tabindex="-1"></a>        mutated_subset <span class="op">=</span> mutate(base_subset)</span>
<span id="cb23-152"><a href="#cb23-152" aria-hidden="true" tabindex="-1"></a>        new_population.append(mutated_subset)</span>
<span id="cb23-153"><a href="#cb23-153" aria-hidden="true" tabindex="-1"></a>    population <span class="op">=</span> new_population</span>
<span id="cb23-154"><a href="#cb23-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-155"><a href="#cb23-155" aria-hidden="true" tabindex="-1"></a><span class="co"># === RESULTADOS ===</span></span>
<span id="cb23-156"><a href="#cb23-156" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb23-157"><a href="#cb23-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-158"><a href="#cb23-158" aria-hidden="true" tabindex="-1"></a><span class="co"># === Guardar en archivo acumulativo ===</span></span>
<span id="cb23-159"><a href="#cb23-159" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> os.path.exists(results_log_file):</span>
<span id="cb23-160"><a href="#cb23-160" aria-hidden="true" tabindex="-1"></a>    combined_df <span class="op">=</span> pd.concat([existing_df, results_df], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-161"><a href="#cb23-161" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb23-162"><a href="#cb23-162" aria-hidden="true" tabindex="-1"></a>    combined_df <span class="op">=</span> results_df</span>
<span id="cb23-163"><a href="#cb23-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-164"><a href="#cb23-164" aria-hidden="true" tabindex="-1"></a>combined_df.to_csv(results_log_file, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-165"><a href="#cb23-165" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">💾 Resultados guardados en: </span><span class="sc">{</span>results_log_file<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-166"><a href="#cb23-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-167"><a href="#cb23-167" aria-hidden="true" tabindex="-1"></a><span class="co"># === Visualizaciones ===</span></span>
<span id="cb23-168"><a href="#cb23-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-169"><a href="#cb23-169" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Evolución del Accuracy</span></span>
<span id="cb23-170"><a href="#cb23-170" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb23-171"><a href="#cb23-171" aria-hidden="true" tabindex="-1"></a>sns.lineplot(x<span class="op">=</span><span class="st">"generation"</span>, y<span class="op">=</span><span class="st">"accuracy"</span>, data<span class="op">=</span>results_df, marker<span class="op">=</span><span class="st">"o"</span>)</span>
<span id="cb23-172"><a href="#cb23-172" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Evolución del Accuracy - Clasificador: </span><span class="sc">{</span>config[<span class="st">'classifier_name'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-173"><a href="#cb23-173" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Generación"</span>)</span>
<span id="cb23-174"><a href="#cb23-174" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Accuracy"</span>)</span>
<span id="cb23-175"><a href="#cb23-175" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb23-176"><a href="#cb23-176" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb23-177"><a href="#cb23-177" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-178"><a href="#cb23-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-179"><a href="#cb23-179" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Distribución del Tamaño de Subconjuntos</span></span>
<span id="cb23-180"><a href="#cb23-180" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb23-181"><a href="#cb23-181" aria-hidden="true" tabindex="-1"></a>sns.histplot(results_df[<span class="st">"subset_size"</span>], bins<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb23-182"><a href="#cb23-182" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribución del Tamaño de Subconjuntos Evaluados"</span>)</span>
<span id="cb23-183"><a href="#cb23-183" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Tamaño del Subconjunto"</span>)</span>
<span id="cb23-184"><a href="#cb23-184" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frecuencia"</span>)</span>
<span id="cb23-185"><a href="#cb23-185" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb23-186"><a href="#cb23-186" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-187"><a href="#cb23-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-188"><a href="#cb23-188" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Top 5 subconjuntos</span></span>
<span id="cb23-189"><a href="#cb23-189" aria-hidden="true" tabindex="-1"></a>top_results <span class="op">=</span> results_df.sort_values(by<span class="op">=</span><span class="st">"accuracy"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">5</span>)</span>
<span id="cb23-190"><a href="#cb23-190" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"🔝 Top 5 subconjuntos con mayor accuracy:"</span>)</span>
<span id="cb23-191"><a href="#cb23-191" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_results[[<span class="st">"generation"</span>, <span class="st">"accuracy"</span>, <span class="st">"f1_score"</span>, <span class="st">"subset_size"</span>, <span class="st">"features"</span>]])</span>
<span id="cb23-192"><a href="#cb23-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-193"><a href="#cb23-193" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Frecuencia de Selección de Características</span></span>
<span id="cb23-194"><a href="#cb23-194" aria-hidden="true" tabindex="-1"></a>feature_counter <span class="op">=</span> Counter()</span>
<span id="cb23-195"><a href="#cb23-195" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> results_df[<span class="st">"features"</span>]:</span>
<span id="cb23-196"><a href="#cb23-196" aria-hidden="true" tabindex="-1"></a>    feature_counter.update(row)</span>
<span id="cb23-197"><a href="#cb23-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-198"><a href="#cb23-198" aria-hidden="true" tabindex="-1"></a>freq_df <span class="op">=</span> pd.DataFrame.from_dict(feature_counter, orient<span class="op">=</span><span class="st">'index'</span>, columns<span class="op">=</span>[<span class="st">"frequency"</span>])</span>
<span id="cb23-199"><a href="#cb23-199" aria-hidden="true" tabindex="-1"></a>freq_df <span class="op">=</span> freq_df.sort_values(by<span class="op">=</span><span class="st">"frequency"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-200"><a href="#cb23-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-201"><a href="#cb23-201" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb23-202"><a href="#cb23-202" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>freq_df.index, y<span class="op">=</span><span class="st">"frequency"</span>, data<span class="op">=</span>freq_df)</span>
<span id="cb23-203"><a href="#cb23-203" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb23-204"><a href="#cb23-204" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Frecuencia de Selección de Características"</span>)</span>
<span id="cb23-205"><a href="#cb23-205" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Características"</span>)</span>
<span id="cb23-206"><a href="#cb23-206" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frecuencia"</span>)</span>
<span id="cb23-207"><a href="#cb23-207" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb23-208"><a href="#cb23-208" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-209"><a href="#cb23-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-210"><a href="#cb23-210" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Mejor subconjunto</span></span>
<span id="cb23-211"><a href="#cb23-211" aria-hidden="true" tabindex="-1"></a>best_result <span class="op">=</span> results_df.loc[results_df[<span class="st">'accuracy'</span>].idxmax()]</span>
<span id="cb23-212"><a href="#cb23-212" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">✅ Mejor subconjunto de características:"</span>)</span>
<span id="cb23-213"><a href="#cb23-213" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>best_result[<span class="st">'accuracy'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb23-214"><a href="#cb23-214" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Características seleccionadas:"</span>)</span>
<span id="cb23-215"><a href="#cb23-215" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_result[<span class="st">'features'</span>])</span>
<span id="cb23-216"><a href="#cb23-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-217"><a href="#cb23-217" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Tabla resumen acumulada</span></span>
<span id="cb23-218"><a href="#cb23-218" aria-hidden="true" tabindex="-1"></a>summary <span class="op">=</span> results_df.groupby(<span class="st">"experiment_id"</span>).agg({</span>
<span id="cb23-219"><a href="#cb23-219" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classifier"</span>: <span class="st">"first"</span>,</span>
<span id="cb23-220"><a href="#cb23-220" aria-hidden="true" tabindex="-1"></a>    <span class="st">"accuracy"</span>: [<span class="st">"max"</span>, <span class="st">"mean"</span>],</span>
<span id="cb23-221"><a href="#cb23-221" aria-hidden="true" tabindex="-1"></a>    <span class="st">"f1_score"</span>: <span class="st">"mean"</span>,</span>
<span id="cb23-222"><a href="#cb23-222" aria-hidden="true" tabindex="-1"></a>    <span class="st">"subset_size"</span>: <span class="st">"mean"</span>,</span>
<span id="cb23-223"><a href="#cb23-223" aria-hidden="true" tabindex="-1"></a>    <span class="st">"generation"</span>: <span class="st">"count"</span></span>
<span id="cb23-224"><a href="#cb23-224" aria-hidden="true" tabindex="-1"></a>}).reset_index()</span>
<span id="cb23-225"><a href="#cb23-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-226"><a href="#cb23-226" aria-hidden="true" tabindex="-1"></a>summary.columns <span class="op">=</span> [</span>
<span id="cb23-227"><a href="#cb23-227" aria-hidden="true" tabindex="-1"></a>    <span class="st">"experiment_id"</span>, <span class="st">"classifier"</span>, <span class="st">"max_accuracy"</span>, <span class="st">"mean_accuracy"</span>,</span>
<span id="cb23-228"><a href="#cb23-228" aria-hidden="true" tabindex="-1"></a>    <span class="st">"mean_f1_score"</span>, <span class="st">"mean_subset_size"</span>, <span class="st">"total_generations"</span></span>
<span id="cb23-229"><a href="#cb23-229" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb23-230"><a href="#cb23-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-231"><a href="#cb23-231" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Tabla de resultados acumulados:"</span>)</span>
<span id="cb23-232"><a href="#cb23-232" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
💾 Resultados guardados en: results_log.csv</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-10-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>🔝 Top 5 subconjuntos con mayor accuracy:
      generation  accuracy  f1_score  subset_size  \
2383         596  0.897917  0.897883            5   
2382         596  0.897917  0.897883            5   
2381         596  0.897917  0.897883            5   
2380         596  0.897917  0.897883            5   
2379         595  0.897917  0.897883            5   

                                               features  
2383  [feature_16, feature_28, feature_30, feature_3...  
2382  [feature_16, feature_28, feature_30, feature_3...  
2381  [feature_16, feature_28, feature_30, feature_3...  
2380  [feature_16, feature_28, feature_30, feature_3...  
2379  [feature_16, feature_28, feature_30, feature_3...  </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-10-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
✅ Mejor subconjunto de características:
Accuracy: 0.8979
Características seleccionadas:
['feature_16', 'feature_28', 'feature_30', 'feature_3', np.str_('feature_20')]

📊 Tabla de resultados acumulados:
   experiment_id    classifier  max_accuracy  mean_accuracy  mean_f1_score  \
0              2  DecisionTree      0.897917       0.897109       0.897072   

   mean_subset_size  total_generations  
0          5.004583               2400  </code></pre>
</div>
</div>
<div id="cell-17" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, ExtraTreesClassifier</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.discriminant_analysis <span class="im">import</span> QuadraticDiscriminantAnalysis</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, f1_score, confusion_matrix, classification_report</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="co"># === CONFIGURACIÓN DEL EXPERIMENTO ===</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> {</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"experiment_id"</span>: <span class="dv">1</span>,</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">"num_generations"</span>: <span class="dv">50</span>,</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">"population_size"</span>: <span class="dv">20</span>,</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">"subset_size_range"</span>: (<span class="dv">5</span>, <span class="dv">10</span>),</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">"elite_fraction"</span>: <span class="fl">0.2</span>,</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">"mutation_rate"</span>: <span class="fl">0.3</span>,</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classifier_name"</span>: <span class="st">"SVM"</span>,</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">"random_state"</span>: <span class="dv">42</span></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a><span class="co"># === CARGA DE DATOS ===</span></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>data_file <span class="op">=</span> <span class="st">"Data_fil_resultstransformed_data.csv"</span></span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(data_file):</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">FileNotFoundError</span>(<span class="ss">f"El archivo </span><span class="sc">{</span>data_file<span class="sc">}</span><span class="ss"> no se encuentra en el directorio actual."</span>)</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(data_file)</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">"target"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"target"</span>]</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> <span class="bu">list</span>(X.columns)</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a><span class="co"># === CARGA DE HISTORIAL DE RESULTADOS ===</span></span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>history_file <span class="op">=</span> <span class="st">"graper_results_history.csv"</span></span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> os.path.exists(history_file):</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>    history_df <span class="op">=</span> pd.read_csv(history_file)</span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>    last_experiment_id <span class="op">=</span> history_df[<span class="st">"experiment_id"</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>    history_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>    last_experiment_id <span class="op">=</span> config[<span class="st">"experiment_id"</span>]</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>config[<span class="st">"experiment_id"</span>] <span class="op">=</span> last_experiment_id</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a><span class="co"># === CLASIFICADOR ===</span></span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_classifier(name, seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name <span class="op">==</span> <span class="st">"RandomForest"</span>:</span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"SVM"</span>:</span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, probability<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"LogisticRegression"</span>:</span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"KNN"</span>:</span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">7</span>)</span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"DecisionTree"</span>:</span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> DecisionTreeClassifier(random_state<span class="op">=</span>seed)</span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"ExtraTrees"</span>:</span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ExtraTreesClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb27-68"><a href="#cb27-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"NaiveBayes"</span>:</span>
<span id="cb27-69"><a href="#cb27-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> GaussianNB()</span>
<span id="cb27-70"><a href="#cb27-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"MLP"</span>:</span>
<span id="cb27-71"><a href="#cb27-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> MLPClassifier(hidden_layer_sizes<span class="op">=</span>(<span class="dv">100</span>,), max_iter<span class="op">=</span><span class="dv">500</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb27-72"><a href="#cb27-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"QDA"</span>:</span>
<span id="cb27-73"><a href="#cb27-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> QuadraticDiscriminantAnalysis()</span>
<span id="cb27-74"><a href="#cb27-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb27-75"><a href="#cb27-75" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Clasificador no reconocido"</span>)</span>
<span id="cb27-76"><a href="#cb27-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-77"><a href="#cb27-77" aria-hidden="true" tabindex="-1"></a><span class="co"># === EVALUACIÓN ===</span></span>
<span id="cb27-78"><a href="#cb27-78" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_subset(features, classifier):</span>
<span id="cb27-79"><a href="#cb27-79" aria-hidden="true" tabindex="-1"></a>    X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb27-80"><a href="#cb27-80" aria-hidden="true" tabindex="-1"></a>        X[features], y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span>config[<span class="st">"random_state"</span>]</span>
<span id="cb27-81"><a href="#cb27-81" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb27-82"><a href="#cb27-82" aria-hidden="true" tabindex="-1"></a>    classifier.fit(X_train, y_train)</span>
<span id="cb27-83"><a href="#cb27-83" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> classifier.predict(X_test)</span>
<span id="cb27-84"><a href="#cb27-84" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb27-85"><a href="#cb27-85" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> f1_score(y_test, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb27-86"><a href="#cb27-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> acc, f1, y_test, y_pred</span>
<span id="cb27-87"><a href="#cb27-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-88"><a href="#cb27-88" aria-hidden="true" tabindex="-1"></a><span class="co"># === POBLACIÓN INICIAL ===</span></span>
<span id="cb27-89"><a href="#cb27-89" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_population(prob_dist, size):</span>
<span id="cb27-90"><a href="#cb27-90" aria-hidden="true" tabindex="-1"></a>    population <span class="op">=</span> []</span>
<span id="cb27-91"><a href="#cb27-91" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(size):</span>
<span id="cb27-92"><a href="#cb27-92" aria-hidden="true" tabindex="-1"></a>        subset_size <span class="op">=</span> random.randint(<span class="op">*</span>config[<span class="st">"subset_size_range"</span>])</span>
<span id="cb27-93"><a href="#cb27-93" aria-hidden="true" tabindex="-1"></a>        selected <span class="op">=</span> np.random.choice(feature_names, size<span class="op">=</span>subset_size, replace<span class="op">=</span><span class="va">False</span>, p<span class="op">=</span>prob_dist)</span>
<span id="cb27-94"><a href="#cb27-94" aria-hidden="true" tabindex="-1"></a>        population.append(<span class="bu">list</span>(selected))</span>
<span id="cb27-95"><a href="#cb27-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> population</span>
<span id="cb27-96"><a href="#cb27-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-97"><a href="#cb27-97" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mutate(subset):</span>
<span id="cb27-98"><a href="#cb27-98" aria-hidden="true" tabindex="-1"></a>    mutated <span class="op">=</span> subset.copy()</span>
<span id="cb27-99"><a href="#cb27-99" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> random.random() <span class="op">&lt;</span> config[<span class="st">"mutation_rate"</span>]:</span>
<span id="cb27-100"><a href="#cb27-100" aria-hidden="true" tabindex="-1"></a>        idx_to_replace <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="bu">len</span>(mutated)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb27-101"><a href="#cb27-101" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Selecciona un nuevo feature no presente en subset</span></span>
<span id="cb27-102"><a href="#cb27-102" aria-hidden="true" tabindex="-1"></a>        new_feature <span class="op">=</span> random.choice([f <span class="cf">for</span> f <span class="kw">in</span> feature_names <span class="cf">if</span> f <span class="kw">not</span> <span class="kw">in</span> mutated])</span>
<span id="cb27-103"><a href="#cb27-103" aria-hidden="true" tabindex="-1"></a>        mutated[idx_to_replace] <span class="op">=</span> new_feature</span>
<span id="cb27-104"><a href="#cb27-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mutated</span>
<span id="cb27-105"><a href="#cb27-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-106"><a href="#cb27-106" aria-hidden="true" tabindex="-1"></a>initial_prob <span class="op">=</span> np.ones(<span class="bu">len</span>(feature_names)) <span class="op">/</span> <span class="bu">len</span>(feature_names)</span>
<span id="cb27-107"><a href="#cb27-107" aria-hidden="true" tabindex="-1"></a>population <span class="op">=</span> generate_population(initial_prob, config[<span class="st">"population_size"</span>])</span>
<span id="cb27-108"><a href="#cb27-108" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb27-109"><a href="#cb27-109" aria-hidden="true" tabindex="-1"></a>accuracy_history <span class="op">=</span> []</span>
<span id="cb27-110"><a href="#cb27-110" aria-hidden="true" tabindex="-1"></a>f1_history <span class="op">=</span> []</span>
<span id="cb27-111"><a href="#cb27-111" aria-hidden="true" tabindex="-1"></a>best_y_test, best_y_pred <span class="op">=</span> <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb27-112"><a href="#cb27-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-113"><a href="#cb27-113" aria-hidden="true" tabindex="-1"></a><span class="co"># === EVOLUCIÓN ===</span></span>
<span id="cb27-114"><a href="#cb27-114" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> gen <span class="kw">in</span> <span class="bu">range</span>(config[<span class="st">"num_generations"</span>]):</span>
<span id="cb27-115"><a href="#cb27-115" aria-hidden="true" tabindex="-1"></a>    gen_results <span class="op">=</span> []</span>
<span id="cb27-116"><a href="#cb27-116" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> subset <span class="kw">in</span> population:</span>
<span id="cb27-117"><a href="#cb27-117" aria-hidden="true" tabindex="-1"></a>        acc_nb, _, _, _ <span class="op">=</span> evaluate_subset(subset, GaussianNB())</span>
<span id="cb27-118"><a href="#cb27-118" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> acc_nb <span class="op">&lt;</span> <span class="fl">0.5</span>:</span>
<span id="cb27-119"><a href="#cb27-119" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb27-120"><a href="#cb27-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-121"><a href="#cb27-121" aria-hidden="true" tabindex="-1"></a>        clf <span class="op">=</span> get_classifier(config[<span class="st">"classifier_name"</span>], config[<span class="st">"random_state"</span>])</span>
<span id="cb27-122"><a href="#cb27-122" aria-hidden="true" tabindex="-1"></a>        acc_rf, f1_rf, y_test, y_pred <span class="op">=</span> evaluate_subset(subset, clf)</span>
<span id="cb27-123"><a href="#cb27-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-124"><a href="#cb27-124" aria-hidden="true" tabindex="-1"></a>        gen_results.append({</span>
<span id="cb27-125"><a href="#cb27-125" aria-hidden="true" tabindex="-1"></a>            <span class="st">"experiment_id"</span>: config[<span class="st">"experiment_id"</span>],</span>
<span id="cb27-126"><a href="#cb27-126" aria-hidden="true" tabindex="-1"></a>            <span class="st">"generation"</span>: gen <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb27-127"><a href="#cb27-127" aria-hidden="true" tabindex="-1"></a>            <span class="st">"features"</span>: subset,</span>
<span id="cb27-128"><a href="#cb27-128" aria-hidden="true" tabindex="-1"></a>            <span class="st">"accuracy"</span>: acc_rf,</span>
<span id="cb27-129"><a href="#cb27-129" aria-hidden="true" tabindex="-1"></a>            <span class="st">"f1_score"</span>: f1_rf,</span>
<span id="cb27-130"><a href="#cb27-130" aria-hidden="true" tabindex="-1"></a>            <span class="st">"subset_size"</span>: <span class="bu">len</span>(subset),</span>
<span id="cb27-131"><a href="#cb27-131" aria-hidden="true" tabindex="-1"></a>            <span class="st">"classifier"</span>: config[<span class="st">"classifier_name"</span>]</span>
<span id="cb27-132"><a href="#cb27-132" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb27-133"><a href="#cb27-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-134"><a href="#cb27-134" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> gen_results:</span>
<span id="cb27-135"><a href="#cb27-135" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb27-136"><a href="#cb27-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-137"><a href="#cb27-137" aria-hidden="true" tabindex="-1"></a>    gen_results.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">"accuracy"</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb27-138"><a href="#cb27-138" aria-hidden="true" tabindex="-1"></a>    elite_count <span class="op">=</span> <span class="bu">max</span>(<span class="dv">1</span>, <span class="bu">int</span>(config[<span class="st">"elite_fraction"</span>] <span class="op">*</span> <span class="bu">len</span>(gen_results)))</span>
<span id="cb27-139"><a href="#cb27-139" aria-hidden="true" tabindex="-1"></a>    elites <span class="op">=</span> gen_results[:elite_count]</span>
<span id="cb27-140"><a href="#cb27-140" aria-hidden="true" tabindex="-1"></a>    results.extend(elites)</span>
<span id="cb27-141"><a href="#cb27-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-142"><a href="#cb27-142" aria-hidden="true" tabindex="-1"></a>    accuracy_history.append(elites[<span class="dv">0</span>][<span class="st">"accuracy"</span>])</span>
<span id="cb27-143"><a href="#cb27-143" aria-hidden="true" tabindex="-1"></a>    f1_history.append(elites[<span class="dv">0</span>][<span class="st">"f1_score"</span>])</span>
<span id="cb27-144"><a href="#cb27-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-145"><a href="#cb27-145" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> elites[<span class="dv">0</span>][<span class="st">"accuracy"</span>] <span class="op">&gt;=</span> <span class="bu">max</span>(accuracy_history):</span>
<span id="cb27-146"><a href="#cb27-146" aria-hidden="true" tabindex="-1"></a>        best_y_test, best_y_pred <span class="op">=</span> y_test, y_pred</span>
<span id="cb27-147"><a href="#cb27-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-148"><a href="#cb27-148" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Gen </span><span class="sc">{</span>gen<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>config[<span class="st">'num_generations'</span>]<span class="sc">}</span><span class="ss">: Mejor Accuracy = </span><span class="sc">{</span>elites[<span class="dv">0</span>][<span class="st">'accuracy'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb27-149"><a href="#cb27-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-150"><a href="#cb27-150" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Actualizar distribución de probabilidad según frecuencia de features en elites</span></span>
<span id="cb27-151"><a href="#cb27-151" aria-hidden="true" tabindex="-1"></a>    feature_counter <span class="op">=</span> Counter()</span>
<span id="cb27-152"><a href="#cb27-152" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> elite <span class="kw">in</span> elites:</span>
<span id="cb27-153"><a href="#cb27-153" aria-hidden="true" tabindex="-1"></a>        feature_counter.update(elite[<span class="st">"features"</span>])</span>
<span id="cb27-154"><a href="#cb27-154" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="bu">sum</span>(feature_counter.values())</span>
<span id="cb27-155"><a href="#cb27-155" aria-hidden="true" tabindex="-1"></a>    prob_dist <span class="op">=</span> np.array([feature_counter.get(f, <span class="dv">0</span>) <span class="op">/</span> total <span class="cf">for</span> f <span class="kw">in</span> feature_names])</span>
<span id="cb27-156"><a href="#cb27-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-157"><a href="#cb27-157" aria-hidden="true" tabindex="-1"></a>    new_population <span class="op">=</span> []</span>
<span id="cb27-158"><a href="#cb27-158" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(new_population) <span class="op">&lt;</span> config[<span class="st">"population_size"</span>]:</span>
<span id="cb27-159"><a href="#cb27-159" aria-hidden="true" tabindex="-1"></a>        base_subset <span class="op">=</span> random.choice(elites)[<span class="st">"features"</span>]</span>
<span id="cb27-160"><a href="#cb27-160" aria-hidden="true" tabindex="-1"></a>        mutated_subset <span class="op">=</span> mutate(base_subset)</span>
<span id="cb27-161"><a href="#cb27-161" aria-hidden="true" tabindex="-1"></a>        new_population.append(mutated_subset)</span>
<span id="cb27-162"><a href="#cb27-162" aria-hidden="true" tabindex="-1"></a>    population <span class="op">=</span> new_population</span>
<span id="cb27-163"><a href="#cb27-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-164"><a href="#cb27-164" aria-hidden="true" tabindex="-1"></a><span class="co"># === RESULTADOS ===</span></span>
<span id="cb27-165"><a href="#cb27-165" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb27-166"><a href="#cb27-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-167"><a href="#cb27-167" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar evolución accuracy y f1</span></span>
<span id="cb27-168"><a href="#cb27-168" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb27-169"><a href="#cb27-169" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(accuracy_history)<span class="op">+</span><span class="dv">1</span>), accuracy_history, label<span class="op">=</span><span class="st">"Accuracy"</span>, marker<span class="op">=</span><span class="st">"o"</span>)</span>
<span id="cb27-170"><a href="#cb27-170" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(f1_history)<span class="op">+</span><span class="dv">1</span>), f1_history, label<span class="op">=</span><span class="st">"F1-Score"</span>, marker<span class="op">=</span><span class="st">"x"</span>)</span>
<span id="cb27-171"><a href="#cb27-171" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Generación"</span>)</span>
<span id="cb27-172"><a href="#cb27-172" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Score"</span>)</span>
<span id="cb27-173"><a href="#cb27-173" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Evolución de Métricas"</span>)</span>
<span id="cb27-174"><a href="#cb27-174" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb27-175"><a href="#cb27-175" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb27-176"><a href="#cb27-176" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb27-177"><a href="#cb27-177" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb27-178"><a href="#cb27-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-179"><a href="#cb27-179" aria-hidden="true" tabindex="-1"></a><span class="co"># Imprimir matriz de confusión y reporte clasificación del mejor resultado</span></span>
<span id="cb27-180"><a href="#cb27-180" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_y_test <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> best_y_pred <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb27-181"><a href="#cb27-181" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">✅ Matriz de Confusión del Mejor Subconjunto:"</span>)</span>
<span id="cb27-182"><a href="#cb27-182" aria-hidden="true" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(best_y_test, best_y_pred)</span>
<span id="cb27-183"><a href="#cb27-183" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(cm)</span>
<span id="cb27-184"><a href="#cb27-184" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📋 Reporte de Clasificación:"</span>)</span>
<span id="cb27-185"><a href="#cb27-185" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(classification_report(best_y_test, best_y_pred))</span>
<span id="cb27-186"><a href="#cb27-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-187"><a href="#cb27-187" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mostrar matriz de confusión con seaborn para mejor visualización</span></span>
<span id="cb27-188"><a href="#cb27-188" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">5</span>))</span>
<span id="cb27-189"><a href="#cb27-189" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb27-190"><a href="#cb27-190" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Matriz de Confusión - Mejor Modelo"</span>)</span>
<span id="cb27-191"><a href="#cb27-191" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Predicción"</span>)</span>
<span id="cb27-192"><a href="#cb27-192" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Real"</span>)</span>
<span id="cb27-193"><a href="#cb27-193" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb27-194"><a href="#cb27-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-195"><a href="#cb27-195" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar top 5 mejores subconjuntos ordenados por accuracy</span></span>
<span id="cb27-196"><a href="#cb27-196" aria-hidden="true" tabindex="-1"></a>top_results <span class="op">=</span> results_df.sort_values(by<span class="op">=</span><span class="st">"accuracy"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">5</span>)</span>
<span id="cb27-197"><a href="#cb27-197" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🔝 Top 5 subconjuntos con mayor accuracy:"</span>)</span>
<span id="cb27-198"><a href="#cb27-198" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_results[[<span class="st">"generation"</span>, <span class="st">"accuracy"</span>, <span class="st">"f1_score"</span>, <span class="st">"subset_size"</span>]])</span>
<span id="cb27-199"><a href="#cb27-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-200"><a href="#cb27-200" aria-hidden="true" tabindex="-1"></a><span class="co"># Contar frecuencia de características en top 5 subconjuntos y ordenarlas por frecuencia descendente</span></span>
<span id="cb27-201"><a href="#cb27-201" aria-hidden="true" tabindex="-1"></a>top_features_counter <span class="op">=</span> Counter()</span>
<span id="cb27-202"><a href="#cb27-202" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> features_list <span class="kw">in</span> top_results[<span class="st">"features"</span>]:</span>
<span id="cb27-203"><a href="#cb27-203" aria-hidden="true" tabindex="-1"></a>    top_features_counter.update(features_list)</span>
<span id="cb27-204"><a href="#cb27-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-205"><a href="#cb27-205" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Características seleccionadas en los 5 mejores subconjuntos ordenadas por frecuencia:"</span>)</span>
<span id="cb27-206"><a href="#cb27-206" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feat, freq <span class="kw">in</span> top_features_counter.most_common():</span>
<span id="cb27-207"><a href="#cb27-207" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>feat<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>freq<span class="sc">}</span><span class="ss"> veces"</span>)</span>
<span id="cb27-208"><a href="#cb27-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-209"><a href="#cb27-209" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar gráfico de frecuencia para características de los top 5</span></span>
<span id="cb27-210"><a href="#cb27-210" aria-hidden="true" tabindex="-1"></a>top_freq_df <span class="op">=</span> pd.DataFrame.from_dict(top_features_counter, orient<span class="op">=</span><span class="st">'index'</span>, columns<span class="op">=</span>[<span class="st">"frequency"</span>])</span>
<span id="cb27-211"><a href="#cb27-211" aria-hidden="true" tabindex="-1"></a>top_freq_df <span class="op">=</span> top_freq_df.sort_values(by<span class="op">=</span><span class="st">"frequency"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-212"><a href="#cb27-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-213"><a href="#cb27-213" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb27-214"><a href="#cb27-214" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>top_freq_df.index, y<span class="op">=</span><span class="st">"frequency"</span>, data<span class="op">=</span>top_freq_df)</span>
<span id="cb27-215"><a href="#cb27-215" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb27-216"><a href="#cb27-216" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Frecuencia de Selección de Características en Top 5 Subconjuntos"</span>)</span>
<span id="cb27-217"><a href="#cb27-217" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Características"</span>)</span>
<span id="cb27-218"><a href="#cb27-218" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frecuencia"</span>)</span>
<span id="cb27-219"><a href="#cb27-219" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb27-220"><a href="#cb27-220" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb27-221"><a href="#cb27-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-222"><a href="#cb27-222" aria-hidden="true" tabindex="-1"></a><span class="co"># Frecuencia total de características en todos los resultados</span></span>
<span id="cb27-223"><a href="#cb27-223" aria-hidden="true" tabindex="-1"></a>feature_counter <span class="op">=</span> Counter()</span>
<span id="cb27-224"><a href="#cb27-224" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> results_df[<span class="st">"features"</span>]:</span>
<span id="cb27-225"><a href="#cb27-225" aria-hidden="true" tabindex="-1"></a>    feature_counter.update(row)</span>
<span id="cb27-226"><a href="#cb27-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-227"><a href="#cb27-227" aria-hidden="true" tabindex="-1"></a>freq_df <span class="op">=</span> pd.DataFrame.from_dict(feature_counter, orient<span class="op">=</span><span class="st">'index'</span>, columns<span class="op">=</span>[<span class="st">"frequency"</span>])</span>
<span id="cb27-228"><a href="#cb27-228" aria-hidden="true" tabindex="-1"></a>freq_df <span class="op">=</span> freq_df.sort_values(by<span class="op">=</span><span class="st">"frequency"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-229"><a href="#cb27-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-230"><a href="#cb27-230" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb27-231"><a href="#cb27-231" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>freq_df.index, y<span class="op">=</span><span class="st">"frequency"</span>, data<span class="op">=</span>freq_df)</span>
<span id="cb27-232"><a href="#cb27-232" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb27-233"><a href="#cb27-233" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Frecuencia de Selección de Características (Total)"</span>)</span>
<span id="cb27-234"><a href="#cb27-234" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Características"</span>)</span>
<span id="cb27-235"><a href="#cb27-235" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frecuencia"</span>)</span>
<span id="cb27-236"><a href="#cb27-236" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb27-237"><a href="#cb27-237" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb27-238"><a href="#cb27-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-239"><a href="#cb27-239" aria-hidden="true" tabindex="-1"></a><span class="co"># Mejor resultado</span></span>
<span id="cb27-240"><a href="#cb27-240" aria-hidden="true" tabindex="-1"></a>best_result <span class="op">=</span> results_df.loc[results_df[<span class="st">'accuracy'</span>].idxmax()]</span>
<span id="cb27-241"><a href="#cb27-241" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">✅ Mejor subconjunto de características:"</span>)</span>
<span id="cb27-242"><a href="#cb27-242" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>best_result[<span class="st">'accuracy'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb27-243"><a href="#cb27-243" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Características seleccionadas (ordenadas por frecuencia global):"</span>)</span>
<span id="cb27-244"><a href="#cb27-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-245"><a href="#cb27-245" aria-hidden="true" tabindex="-1"></a><span class="co"># Ordenar características del mejor resultado según frecuencia global descendente</span></span>
<span id="cb27-246"><a href="#cb27-246" aria-hidden="true" tabindex="-1"></a>best_feats <span class="op">=</span> best_result[<span class="st">'features'</span>]</span>
<span id="cb27-247"><a href="#cb27-247" aria-hidden="true" tabindex="-1"></a>best_feats_sorted <span class="op">=</span> <span class="bu">sorted</span>(best_feats, key<span class="op">=</span><span class="kw">lambda</span> f: feature_counter.get(f, <span class="dv">0</span>), reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb27-248"><a href="#cb27-248" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_feats_sorted)</span>
<span id="cb27-249"><a href="#cb27-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-250"><a href="#cb27-250" aria-hidden="true" tabindex="-1"></a>summary <span class="op">=</span> results_df.groupby(<span class="st">"experiment_id"</span>).agg({</span>
<span id="cb27-251"><a href="#cb27-251" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classifier"</span>: <span class="st">"first"</span>,</span>
<span id="cb27-252"><a href="#cb27-252" aria-hidden="true" tabindex="-1"></a>    <span class="st">"accuracy"</span>: [<span class="st">"max"</span>, <span class="st">"mean"</span>],</span>
<span id="cb27-253"><a href="#cb27-253" aria-hidden="true" tabindex="-1"></a>    <span class="st">"f1_score"</span>: <span class="st">"mean"</span>,</span>
<span id="cb27-254"><a href="#cb27-254" aria-hidden="true" tabindex="-1"></a>    <span class="st">"subset_size"</span>: <span class="st">"mean"</span>,</span>
<span id="cb27-255"><a href="#cb27-255" aria-hidden="true" tabindex="-1"></a>    <span class="st">"generation"</span>: <span class="st">"count"</span></span>
<span id="cb27-256"><a href="#cb27-256" aria-hidden="true" tabindex="-1"></a>}).reset_index()</span>
<span id="cb27-257"><a href="#cb27-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-258"><a href="#cb27-258" aria-hidden="true" tabindex="-1"></a>summary.columns <span class="op">=</span> [</span>
<span id="cb27-259"><a href="#cb27-259" aria-hidden="true" tabindex="-1"></a>    <span class="st">"experiment_id"</span>, <span class="st">"classifier"</span>, <span class="st">"max_accuracy"</span>, <span class="st">"mean_accuracy"</span>,</span>
<span id="cb27-260"><a href="#cb27-260" aria-hidden="true" tabindex="-1"></a>    <span class="st">"mean_f1_score"</span>, <span class="st">"mean_subset_size"</span>, <span class="st">"total_generations"</span></span>
<span id="cb27-261"><a href="#cb27-261" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb27-262"><a href="#cb27-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-263"><a href="#cb27-263" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Tabla de resultados acumulados:"</span>)</span>
<span id="cb27-264"><a href="#cb27-264" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary)</span>
<span id="cb27-265"><a href="#cb27-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-266"><a href="#cb27-266" aria-hidden="true" tabindex="-1"></a><span class="co"># Guardar historial acumulado</span></span>
<span id="cb27-267"><a href="#cb27-267" aria-hidden="true" tabindex="-1"></a>history_df <span class="op">=</span> pd.concat([history_df, results_df], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb27-268"><a href="#cb27-268" aria-hidden="true" tabindex="-1"></a>history_df.to_csv(history_file, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Gen 1/50: Mejor Accuracy = 0.8667
Gen 2/50: Mejor Accuracy = 0.8667
Gen 3/50: Mejor Accuracy = 0.8667
Gen 4/50: Mejor Accuracy = 0.8667
Gen 5/50: Mejor Accuracy = 0.8688
Gen 6/50: Mejor Accuracy = 0.8750
Gen 7/50: Mejor Accuracy = 0.8750
Gen 8/50: Mejor Accuracy = 0.8750
Gen 9/50: Mejor Accuracy = 0.8750
Gen 10/50: Mejor Accuracy = 0.8750
Gen 11/50: Mejor Accuracy = 0.8750
Gen 12/50: Mejor Accuracy = 0.8750
Gen 13/50: Mejor Accuracy = 0.8750
Gen 14/50: Mejor Accuracy = 0.8750
Gen 15/50: Mejor Accuracy = 0.8750
Gen 16/50: Mejor Accuracy = 0.8750
Gen 17/50: Mejor Accuracy = 0.8750
Gen 18/50: Mejor Accuracy = 0.8750
Gen 19/50: Mejor Accuracy = 0.8750
Gen 20/50: Mejor Accuracy = 0.8750
Gen 21/50: Mejor Accuracy = 0.8750
Gen 22/50: Mejor Accuracy = 0.8750
Gen 23/50: Mejor Accuracy = 0.8750
Gen 24/50: Mejor Accuracy = 0.8750
Gen 25/50: Mejor Accuracy = 0.8750
Gen 26/50: Mejor Accuracy = 0.8750
Gen 27/50: Mejor Accuracy = 0.8812
Gen 28/50: Mejor Accuracy = 0.8812
Gen 29/50: Mejor Accuracy = 0.8896
Gen 30/50: Mejor Accuracy = 0.8896
Gen 31/50: Mejor Accuracy = 0.8896
Gen 32/50: Mejor Accuracy = 0.8896
Gen 33/50: Mejor Accuracy = 0.8896
Gen 34/50: Mejor Accuracy = 0.8896
Gen 35/50: Mejor Accuracy = 0.8896
Gen 36/50: Mejor Accuracy = 0.8896
Gen 37/50: Mejor Accuracy = 0.8896
Gen 38/50: Mejor Accuracy = 0.8896
Gen 39/50: Mejor Accuracy = 0.8896
Gen 40/50: Mejor Accuracy = 0.8896
Gen 41/50: Mejor Accuracy = 0.8896
Gen 42/50: Mejor Accuracy = 0.8896
Gen 43/50: Mejor Accuracy = 0.8896
Gen 44/50: Mejor Accuracy = 0.8896
Gen 45/50: Mejor Accuracy = 0.8896
Gen 46/50: Mejor Accuracy = 0.8896
Gen 47/50: Mejor Accuracy = 0.8896
Gen 48/50: Mejor Accuracy = 0.8896
Gen 49/50: Mejor Accuracy = 0.8896
Gen 50/50: Mejor Accuracy = 0.8896</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
✅ Matriz de Confusión del Mejor Subconjunto:
[[200  38]
 [ 15 227]]

📋 Reporte de Clasificación:
              precision    recall  f1-score   support

     Dropout       0.93      0.84      0.88       238
    Graduate       0.86      0.94      0.90       242

    accuracy                           0.89       480
   macro avg       0.89      0.89      0.89       480
weighted avg       0.89      0.89      0.89       480
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-11-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
🔝 Top 5 subconjuntos con mayor accuracy:
     generation  accuracy  f1_score  subset_size
191          48  0.889583  0.889285            6
190          48  0.889583  0.889285            6
189          48  0.889583  0.889285            6
188          48  0.889583  0.889285            6
187          47  0.889583  0.889285            6

Características seleccionadas en los 5 mejores subconjuntos ordenadas por frecuencia:
feature_16: 5 veces
feature_30: 5 veces
feature_18: 5 veces
feature_14: 5 veces
feature_3: 5 veces
feature_23: 5 veces</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-11-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-11-output-7.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
✅ Mejor subconjunto de características:
Accuracy: 0.8896
Características seleccionadas (ordenadas por frecuencia global):
[np.str_('feature_30'), np.str_('feature_23'), np.str_('feature_18'), np.str_('feature_3'), 'feature_16', 'feature_14']

📊 Tabla de resultados acumulados:
   experiment_id classifier  max_accuracy  mean_accuracy  mean_f1_score  \
0              1        SVM      0.889583       0.879927       0.879707   

   mean_subset_size  total_generations  
0              6.02                200  </code></pre>
</div>
</div>
</section>
<section id="prueba-de-rejilla-para-seleccion-de-modelo" class="level1">
<h1>PRUEBA DE REJILLA PARA SELECCION DE MODELO</h1>
<div id="cell-19" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, GridSearchCV</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> joblib</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Cargar datos ---</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">'Data_fil_resultstransformed_data.csv'</span>)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dataset cargado: </span><span class="sc">{</span>data<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> muestras, </span><span class="sc">{</span>data<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> características."</span>)</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data.drop(columns<span class="op">=</span>[<span class="st">'target'</span>])  <span class="co"># Cambia 'target' por el nombre real de tu columna objetivo</span></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">'target'</span>]</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a><span class="co"># --- División 70% entrenamiento, 30% prueba ---</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y)</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Datos divididos: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> para entrenamiento, </span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> para prueba."</span>)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Clasificadores ---</span></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>classifiers <span class="op">=</span> {</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">'LogisticRegression'</span>: LogisticRegression(max_iter<span class="op">=</span><span class="dv">500</span>),</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">'RandomForest'</span>: RandomForestClassifier(),</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SVC'</span>: SVC(),</span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">'KNeighbors'</span>: KNeighborsClassifier()</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Rejillas de hiperparámetros ---</span></span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a>param_grids <span class="op">=</span> {</span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">'LogisticRegression'</span>: {</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>        <span class="st">'clf__C'</span>: [<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>],</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">'clf__penalty'</span>: [<span class="st">'l2'</span>],</span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a>        <span class="st">'clf__solver'</span>: [<span class="st">'lbfgs'</span>, <span class="st">'saga'</span>]</span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>    <span class="st">'RandomForest'</span>: {</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a>        <span class="st">'clf__n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>],</span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a>        <span class="st">'clf__max_depth'</span>: [<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>],</span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a>        <span class="st">'clf__min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>]</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SVC'</span>: {</span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">'clf__C'</span>: [<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>],</span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">'clf__kernel'</span>: [<span class="st">'linear'</span>, <span class="st">'rbf'</span>],</span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">'clf__gamma'</span>: [<span class="st">'scale'</span>, <span class="st">'auto'</span>]</span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a>    <span class="st">'KNeighbors'</span>: {</span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a>        <span class="st">'clf__n_neighbors'</span>: [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>],</span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a>        <span class="st">'clf__weights'</span>: [<span class="st">'uniform'</span>, <span class="st">'distance'</span>]</span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a>results_summary <span class="op">=</span> []</span>
<span id="cb32-56"><a href="#cb32-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-57"><a href="#cb32-57" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, clf <span class="kw">in</span> classifiers.items():</span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">--- Ejecutando GridSearch para: </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a>    pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'scaler'</span>, StandardScaler()),</span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a>        (<span class="st">'clf'</span>, clf)</span>
<span id="cb32-62"><a href="#cb32-62" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb32-63"><a href="#cb32-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-64"><a href="#cb32-64" aria-hidden="true" tabindex="-1"></a>    grid <span class="op">=</span> GridSearchCV(</span>
<span id="cb32-65"><a href="#cb32-65" aria-hidden="true" tabindex="-1"></a>        pipeline,</span>
<span id="cb32-66"><a href="#cb32-66" aria-hidden="true" tabindex="-1"></a>        param_grid<span class="op">=</span>param_grids[name],</span>
<span id="cb32-67"><a href="#cb32-67" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span>{<span class="st">'accuracy'</span>: <span class="st">'accuracy'</span>, <span class="st">'f1_macro'</span>: <span class="st">'f1_macro'</span>},</span>
<span id="cb32-68"><a href="#cb32-68" aria-hidden="true" tabindex="-1"></a>        refit<span class="op">=</span><span class="st">'accuracy'</span>,</span>
<span id="cb32-69"><a href="#cb32-69" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb32-70"><a href="#cb32-70" aria-hidden="true" tabindex="-1"></a>        n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb32-71"><a href="#cb32-71" aria-hidden="true" tabindex="-1"></a>        verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb32-72"><a href="#cb32-72" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb32-73"><a href="#cb32-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-74"><a href="#cb32-74" aria-hidden="true" tabindex="-1"></a>    grid.fit(X_train, y_train)</span>
<span id="cb32-75"><a href="#cb32-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-76"><a href="#cb32-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mostrar mejores resultados</span></span>
<span id="cb32-77"><a href="#cb32-77" aria-hidden="true" tabindex="-1"></a>    best_acc <span class="op">=</span> grid.best_score_</span>
<span id="cb32-78"><a href="#cb32-78" aria-hidden="true" tabindex="-1"></a>    best_params <span class="op">=</span> grid.best_params_</span>
<span id="cb32-79"><a href="#cb32-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-80"><a href="#cb32-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Obtener el mejor F1-macro asociado al mejor índice</span></span>
<span id="cb32-81"><a href="#cb32-81" aria-hidden="true" tabindex="-1"></a>    best_index <span class="op">=</span> grid.best_index_</span>
<span id="cb32-82"><a href="#cb32-82" aria-hidden="true" tabindex="-1"></a>    best_f1_macro <span class="op">=</span> grid.cv_results_[<span class="st">'mean_test_f1_macro'</span>][best_index]</span>
<span id="cb32-83"><a href="#cb32-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-84"><a href="#cb32-84" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mejor Accuracy para </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>best_acc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb32-85"><a href="#cb32-85" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mejor F1-macro para </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>best_f1_macro<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb32-86"><a href="#cb32-86" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mejores parámetros: </span><span class="sc">{</span>best_params<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-87"><a href="#cb32-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-88"><a href="#cb32-88" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Guardar resumen para comparar luego</span></span>
<span id="cb32-89"><a href="#cb32-89" aria-hidden="true" tabindex="-1"></a>    results_summary.append({</span>
<span id="cb32-90"><a href="#cb32-90" aria-hidden="true" tabindex="-1"></a>        <span class="st">'name'</span>: name,</span>
<span id="cb32-91"><a href="#cb32-91" aria-hidden="true" tabindex="-1"></a>        <span class="st">'best_accuracy'</span>: best_acc,</span>
<span id="cb32-92"><a href="#cb32-92" aria-hidden="true" tabindex="-1"></a>        <span class="st">'best_f1_macro'</span>: best_f1_macro,</span>
<span id="cb32-93"><a href="#cb32-93" aria-hidden="true" tabindex="-1"></a>        <span class="st">'best_params'</span>: best_params,</span>
<span id="cb32-94"><a href="#cb32-94" aria-hidden="true" tabindex="-1"></a>        <span class="st">'best_estimator'</span>: grid.best_estimator_</span>
<span id="cb32-95"><a href="#cb32-95" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb32-96"><a href="#cb32-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-97"><a href="#cb32-97" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mostrar tabla completa de resultados de la rejilla</span></span>
<span id="cb32-98"><a href="#cb32-98" aria-hidden="true" tabindex="-1"></a>    results_df <span class="op">=</span> pd.DataFrame(grid.cv_results_)</span>
<span id="cb32-99"><a href="#cb32-99" aria-hidden="true" tabindex="-1"></a>    cols_to_show <span class="op">=</span> [<span class="st">'params'</span>, <span class="st">'mean_test_accuracy'</span>, <span class="st">'mean_test_f1_macro'</span>]</span>
<span id="cb32-100"><a href="#cb32-100" aria-hidden="true" tabindex="-1"></a>    results_df_to_print <span class="op">=</span> results_df[cols_to_show].sort_values(by<span class="op">=</span><span class="st">'mean_test_accuracy'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb32-101"><a href="#cb32-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-102"><a href="#cb32-102" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Resultados completos para </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb32-103"><a href="#cb32-103" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(results_df_to_print.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb32-104"><a href="#cb32-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-105"><a href="#cb32-105" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Guardar resultados completos a CSV</span></span>
<span id="cb32-106"><a href="#cb32-106" aria-hidden="true" tabindex="-1"></a>    results_df_to_print.to_csv(<span class="ss">f'resultados_grid_</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb32-107"><a href="#cb32-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-108"><a href="#cb32-108" aria-hidden="true" tabindex="-1"></a><span class="co"># Ordenar modelos por mejor accuracy</span></span>
<span id="cb32-109"><a href="#cb32-109" aria-hidden="true" tabindex="-1"></a>results_summary <span class="op">=</span> <span class="bu">sorted</span>(results_summary, key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">'best_accuracy'</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-110"><a href="#cb32-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-111"><a href="#cb32-111" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Resumen de resultados (ordenado por Accuracy) ---"</span>)</span>
<span id="cb32-112"><a href="#cb32-112" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> r <span class="kw">in</span> results_summary:</span>
<span id="cb32-113"><a href="#cb32-113" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>r[<span class="st">'name'</span>]<span class="sc">:15}</span><span class="ss"> | Accuracy: </span><span class="sc">{</span>r[<span class="st">'best_accuracy'</span>]<span class="sc">:.4f}</span><span class="ss"> | F1-macro: </span><span class="sc">{</span>r[<span class="st">'best_f1_macro'</span>]<span class="sc">:.4f}</span><span class="ss"> | Params: </span><span class="sc">{</span>r[<span class="st">'best_params'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-114"><a href="#cb32-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-115"><a href="#cb32-115" aria-hidden="true" tabindex="-1"></a><span class="co"># Mejor modelo global</span></span>
<span id="cb32-116"><a href="#cb32-116" aria-hidden="true" tabindex="-1"></a>best_model_info <span class="op">=</span> results_summary[<span class="dv">0</span>]</span>
<span id="cb32-117"><a href="#cb32-117" aria-hidden="true" tabindex="-1"></a>best_model <span class="op">=</span> best_model_info[<span class="st">'best_estimator'</span>]</span>
<span id="cb32-118"><a href="#cb32-118" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Mejor modelo global: </span><span class="sc">{</span>best_model_info[<span class="st">'name'</span>]<span class="sc">}</span><span class="ss"> con Accuracy </span><span class="sc">{</span>best_model_info[<span class="st">'best_accuracy'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb32-119"><a href="#cb32-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-120"><a href="#cb32-120" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluación en el conjunto de prueba</span></span>
<span id="cb32-121"><a href="#cb32-121" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> best_model.predict(X_test)</span>
<span id="cb32-122"><a href="#cb32-122" aria-hidden="true" tabindex="-1"></a>acc_test <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb32-123"><a href="#cb32-123" aria-hidden="true" tabindex="-1"></a>f1_test <span class="op">=</span> f1_score(y_test, y_pred, average<span class="op">=</span><span class="st">'macro'</span>)</span>
<span id="cb32-124"><a href="#cb32-124" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Evaluación en conjunto de prueba:"</span>)</span>
<span id="cb32-125"><a href="#cb32-125" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>acc_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb32-126"><a href="#cb32-126" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"F1-macro: </span><span class="sc">{</span>f1_test<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb32-127"><a href="#cb32-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-128"><a href="#cb32-128" aria-hidden="true" tabindex="-1"></a><span class="co"># Matriz de confusión en test</span></span>
<span id="cb32-129"><a href="#cb32-129" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb32-130"><a href="#cb32-130" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>best_model.classes_)</span>
<span id="cb32-131"><a href="#cb32-131" aria-hidden="true" tabindex="-1"></a>disp.plot(cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb32-132"><a href="#cb32-132" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f'Matriz de Confusión - Mejor modelo: </span><span class="sc">{</span>best_model_info[<span class="st">"name"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb32-133"><a href="#cb32-133" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb32-134"><a href="#cb32-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-135"><a href="#cb32-135" aria-hidden="true" tabindex="-1"></a><span class="co"># Guardar modelo final</span></span>
<span id="cb32-136"><a href="#cb32-136" aria-hidden="true" tabindex="-1"></a>joblib.dump(best_model, <span class="st">'best_model.joblib'</span>)</span>
<span id="cb32-137"><a href="#cb32-137" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Modelo guardado como 'best_model.joblib'"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset cargado: 1600 muestras, 36 características.
Datos divididos: 1120 para entrenamiento, 480 para prueba.

--- Ejecutando GridSearch para: LogisticRegression ---
Mejor Accuracy para LogisticRegression: 0.8830
Mejor F1-macro para LogisticRegression: 0.8828
Mejores parámetros: {'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}

Resultados completos para LogisticRegression:
                                                       params  mean_test_accuracy  mean_test_f1_macro
  {'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}            0.883036            0.882849
   {'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'saga'}            0.881250            0.881063
 {'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}            0.876786            0.876557
  {'clf__C': 10, 'clf__penalty': 'l2', 'clf__solver': 'saga'}            0.876786            0.876557
 {'clf__C': 0.1, 'clf__penalty': 'l2', 'clf__solver': 'saga'}            0.874107            0.873892
{'clf__C': 0.1, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}            0.874107            0.873892

--- Ejecutando GridSearch para: RandomForest ---
Mejor Accuracy para RandomForest: 0.8982
Mejor F1-macro para RandomForest: 0.8981
Mejores parámetros: {'clf__max_depth': 10, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}

Resultados completos para RandomForest:
                                                                        params  mean_test_accuracy  mean_test_f1_macro
 {'clf__max_depth': 10, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}            0.898214            0.898096
 {'clf__max_depth': 15, 'clf__min_samples_split': 2, 'clf__n_estimators': 200}            0.891964            0.891850
 {'clf__max_depth': 15, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}            0.891964            0.891850
 {'clf__max_depth': 15, 'clf__min_samples_split': 5, 'clf__n_estimators': 300}            0.891964            0.891869
 {'clf__max_depth': 15, 'clf__min_samples_split': 5, 'clf__n_estimators': 200}            0.891071            0.890974
 {'clf__max_depth': 10, 'clf__min_samples_split': 5, 'clf__n_estimators': 200}            0.889286            0.889133
 {'clf__max_depth': 15, 'clf__min_samples_split': 2, 'clf__n_estimators': 300}            0.888393            0.888254
 {'clf__max_depth': 15, 'clf__min_samples_split': 5, 'clf__n_estimators': 100}            0.888393            0.888251
 {'clf__max_depth': 10, 'clf__min_samples_split': 2, 'clf__n_estimators': 300}            0.886607            0.886454
 {'clf__max_depth': 10, 'clf__min_samples_split': 2, 'clf__n_estimators': 200}            0.886607            0.886478
{'clf__max_depth': 15, 'clf__min_samples_split': 10, 'clf__n_estimators': 300}            0.886607            0.886523
{'clf__max_depth': 15, 'clf__min_samples_split': 10, 'clf__n_estimators': 100}            0.886607            0.886515
{'clf__max_depth': 10, 'clf__min_samples_split': 10, 'clf__n_estimators': 300}            0.885714            0.885602
{'clf__max_depth': 15, 'clf__min_samples_split': 10, 'clf__n_estimators': 200}            0.885714            0.885580
{'clf__max_depth': 10, 'clf__min_samples_split': 10, 'clf__n_estimators': 100}            0.885714            0.885568
 {'clf__max_depth': 10, 'clf__min_samples_split': 5, 'clf__n_estimators': 300}            0.883929            0.883792
 {'clf__max_depth': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 200}            0.882143            0.881895
 {'clf__max_depth': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 300}            0.882143            0.881906
{'clf__max_depth': 10, 'clf__min_samples_split': 10, 'clf__n_estimators': 200}            0.881250            0.881122
  {'clf__max_depth': 5, 'clf__min_samples_split': 5, 'clf__n_estimators': 100}            0.880357            0.880138
  {'clf__max_depth': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}            0.879464            0.879244
  {'clf__max_depth': 5, 'clf__min_samples_split': 5, 'clf__n_estimators': 200}            0.879464            0.879256
  {'clf__max_depth': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 200}            0.878571            0.878376
 {'clf__max_depth': 10, 'clf__min_samples_split': 5, 'clf__n_estimators': 100}            0.878571            0.878451
  {'clf__max_depth': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 300}            0.876786            0.876573
  {'clf__max_depth': 5, 'clf__min_samples_split': 5, 'clf__n_estimators': 300}            0.875893            0.875619
 {'clf__max_depth': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 100}            0.872321            0.872057

--- Ejecutando GridSearch para: SVC ---
Mejor Accuracy para SVC: 0.8848
Mejor F1-macro para SVC: 0.8847
Mejores parámetros: {'clf__C': 1, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}

Resultados completos para SVC:
                                                         params  mean_test_accuracy  mean_test_f1_macro
   {'clf__C': 1, 'clf__gamma': 'auto', 'clf__kernel': 'linear'}            0.884821            0.884675
  {'clf__C': 1, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}            0.884821            0.884675
 {'clf__C': 10, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}            0.878571            0.878427
  {'clf__C': 10, 'clf__gamma': 'auto', 'clf__kernel': 'linear'}            0.878571            0.878427
    {'clf__C': 10, 'clf__gamma': 'scale', 'clf__kernel': 'rbf'}            0.874107            0.873944
     {'clf__C': 10, 'clf__gamma': 'auto', 'clf__kernel': 'rbf'}            0.874107            0.873944
 {'clf__C': 0.1, 'clf__gamma': 'auto', 'clf__kernel': 'linear'}            0.874107            0.873905
{'clf__C': 0.1, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}            0.874107            0.873905
      {'clf__C': 1, 'clf__gamma': 'auto', 'clf__kernel': 'rbf'}            0.859821            0.859076
     {'clf__C': 1, 'clf__gamma': 'scale', 'clf__kernel': 'rbf'}            0.859821            0.859076
    {'clf__C': 0.1, 'clf__gamma': 'auto', 'clf__kernel': 'rbf'}            0.813393            0.812753
   {'clf__C': 0.1, 'clf__gamma': 'scale', 'clf__kernel': 'rbf'}            0.813393            0.812753

--- Ejecutando GridSearch para: KNeighbors ---
Mejor Accuracy para KNeighbors: 0.8009
Mejor F1-macro para KNeighbors: 0.7988
Mejores parámetros: {'clf__n_neighbors': 9, 'clf__weights': 'distance'}

Resultados completos para KNeighbors:
                                             params  mean_test_accuracy  mean_test_f1_macro
{'clf__n_neighbors': 9, 'clf__weights': 'distance'}            0.800893            0.798792
 {'clf__n_neighbors': 9, 'clf__weights': 'uniform'}            0.794643            0.792110
 {'clf__n_neighbors': 7, 'clf__weights': 'uniform'}            0.791071            0.789543
{'clf__n_neighbors': 7, 'clf__weights': 'distance'}            0.791071            0.789616
 {'clf__n_neighbors': 5, 'clf__weights': 'uniform'}            0.772321            0.771071
{'clf__n_neighbors': 5, 'clf__weights': 'distance'}            0.771429            0.770161
{'clf__n_neighbors': 3, 'clf__weights': 'distance'}            0.766964            0.766027
 {'clf__n_neighbors': 3, 'clf__weights': 'uniform'}            0.766071            0.765158

--- Resumen de resultados (ordenado por Accuracy) ---
RandomForest    | Accuracy: 0.8982 | F1-macro: 0.8981 | Params: {'clf__max_depth': 10, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}
SVC             | Accuracy: 0.8848 | F1-macro: 0.8847 | Params: {'clf__C': 1, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}
LogisticRegression | Accuracy: 0.8830 | F1-macro: 0.8828 | Params: {'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}
KNeighbors      | Accuracy: 0.8009 | F1-macro: 0.7988 | Params: {'clf__n_neighbors': 9, 'clf__weights': 'distance'}

Mejor modelo global: RandomForest con Accuracy 0.8982

Evaluación en conjunto de prueba:
Accuracy: 0.8917
F1-macro: 0.8914</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-12-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Modelo guardado como 'best_model.joblib'</code></pre>
</div>
</div>
</section>
<section id="prueba-con-modelo-obtenido" class="level1">
<h1>PRUEBA CON MODELO OBTENIDO</h1>
<div id="cell-21" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.discriminant_analysis <span class="im">import</span> QuadraticDiscriminantAnalysis</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, f1_score, confusion_matrix, classification_report</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a><span class="co"># === CONFIGURACIÓN DEL EXPERIMENTO ===</span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> {</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"experiment_id"</span>: <span class="dv">1</span>,</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">"num_generations"</span>: <span class="dv">50</span>,</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">"population_size"</span>: <span class="dv">20</span>,</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">"subset_size_range"</span>: (<span class="dv">5</span>, <span class="dv">10</span>),</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">"elite_fraction"</span>: <span class="fl">0.2</span>,</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">"mutation_rate"</span>: <span class="fl">0.3</span>,</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classifier_name"</span>: <span class="st">"RandomForest"</span>,  <span class="co"># Cambiado a mejor modelo obtenido</span></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">"random_state"</span>: <span class="dv">42</span></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a><span class="co"># === CARGA DE DATOS ===</span></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>data_file <span class="op">=</span> <span class="st">"Data_fil_resultstransformed_data.csv"</span></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(data_file):</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">FileNotFoundError</span>(<span class="ss">f"El archivo </span><span class="sc">{</span>data_file<span class="sc">}</span><span class="ss"> no se encuentra en el directorio actual."</span>)</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(data_file)</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">"target"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"target"</span>]</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> <span class="bu">list</span>(X.columns)</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a><span class="co"># === CARGA DE HISTORIAL DE RESULTADOS ===</span></span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a>history_file <span class="op">=</span> <span class="st">"graper_results_history.csv"</span></span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> os.path.exists(history_file):</span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a>    history_df <span class="op">=</span> pd.read_csv(history_file)</span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>    last_experiment_id <span class="op">=</span> history_df[<span class="st">"experiment_id"</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a>    history_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a>    last_experiment_id <span class="op">=</span> config[<span class="st">"experiment_id"</span>]</span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a>config[<span class="st">"experiment_id"</span>] <span class="op">=</span> last_experiment_id</span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a><span class="co"># === CLASIFICADOR ===</span></span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_classifier(name, seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name <span class="op">==</span> <span class="st">"RandomForest"</span>:</span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Parámetros ajustados ejemplo; poner los que conseguiste en rejilla</span></span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">200</span>, max_depth<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"SVM"</span>:</span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, probability<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"LogisticRegression"</span>:</span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"KNN"</span>:</span>
<span id="cb35-64"><a href="#cb35-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">7</span>)</span>
<span id="cb35-65"><a href="#cb35-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"DecisionTree"</span>:</span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> DecisionTreeClassifier(random_state<span class="op">=</span>seed)</span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"ExtraTrees"</span>:</span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ExtraTreesClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb35-69"><a href="#cb35-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"NaiveBayes"</span>:</span>
<span id="cb35-70"><a href="#cb35-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> GaussianNB()</span>
<span id="cb35-71"><a href="#cb35-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"MLP"</span>:</span>
<span id="cb35-72"><a href="#cb35-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> MLPClassifier(hidden_layer_sizes<span class="op">=</span>(<span class="dv">100</span>,), max_iter<span class="op">=</span><span class="dv">500</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb35-73"><a href="#cb35-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> name <span class="op">==</span> <span class="st">"QDA"</span>:</span>
<span id="cb35-74"><a href="#cb35-74" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> QuadraticDiscriminantAnalysis()</span>
<span id="cb35-75"><a href="#cb35-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb35-76"><a href="#cb35-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Clasificador no reconocido"</span>)</span>
<span id="cb35-77"><a href="#cb35-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-78"><a href="#cb35-78" aria-hidden="true" tabindex="-1"></a><span class="co"># === EVALUACIÓN ===</span></span>
<span id="cb35-79"><a href="#cb35-79" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_subset(features, classifier):</span>
<span id="cb35-80"><a href="#cb35-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Usar 70% entrenamiento, 30% prueba</span></span>
<span id="cb35-81"><a href="#cb35-81" aria-hidden="true" tabindex="-1"></a>    X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb35-82"><a href="#cb35-82" aria-hidden="true" tabindex="-1"></a>        X[features], y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span>config[<span class="st">"random_state"</span>]</span>
<span id="cb35-83"><a href="#cb35-83" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb35-84"><a href="#cb35-84" aria-hidden="true" tabindex="-1"></a>    classifier.fit(X_train, y_train)</span>
<span id="cb35-85"><a href="#cb35-85" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> classifier.predict(X_test)</span>
<span id="cb35-86"><a href="#cb35-86" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb35-87"><a href="#cb35-87" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> f1_score(y_test, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb35-88"><a href="#cb35-88" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> acc, f1, y_test, y_pred</span>
<span id="cb35-89"><a href="#cb35-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-90"><a href="#cb35-90" aria-hidden="true" tabindex="-1"></a><span class="co"># === POBLACIÓN INICIAL ===</span></span>
<span id="cb35-91"><a href="#cb35-91" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_population(prob_dist, size):</span>
<span id="cb35-92"><a href="#cb35-92" aria-hidden="true" tabindex="-1"></a>    population <span class="op">=</span> []</span>
<span id="cb35-93"><a href="#cb35-93" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(size):</span>
<span id="cb35-94"><a href="#cb35-94" aria-hidden="true" tabindex="-1"></a>        subset_size <span class="op">=</span> random.randint(<span class="op">*</span>config[<span class="st">"subset_size_range"</span>])</span>
<span id="cb35-95"><a href="#cb35-95" aria-hidden="true" tabindex="-1"></a>        selected <span class="op">=</span> np.random.choice(feature_names, size<span class="op">=</span>subset_size, replace<span class="op">=</span><span class="va">False</span>, p<span class="op">=</span>prob_dist)</span>
<span id="cb35-96"><a href="#cb35-96" aria-hidden="true" tabindex="-1"></a>        population.append(<span class="bu">list</span>(selected))</span>
<span id="cb35-97"><a href="#cb35-97" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> population</span>
<span id="cb35-98"><a href="#cb35-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-99"><a href="#cb35-99" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mutate(subset):</span>
<span id="cb35-100"><a href="#cb35-100" aria-hidden="true" tabindex="-1"></a>    mutated <span class="op">=</span> subset.copy()</span>
<span id="cb35-101"><a href="#cb35-101" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> random.random() <span class="op">&lt;</span> config[<span class="st">"mutation_rate"</span>]:</span>
<span id="cb35-102"><a href="#cb35-102" aria-hidden="true" tabindex="-1"></a>        idx_to_replace <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="bu">len</span>(mutated)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb35-103"><a href="#cb35-103" aria-hidden="true" tabindex="-1"></a>        new_feature <span class="op">=</span> random.choice([f <span class="cf">for</span> f <span class="kw">in</span> feature_names <span class="cf">if</span> f <span class="kw">not</span> <span class="kw">in</span> mutated])</span>
<span id="cb35-104"><a href="#cb35-104" aria-hidden="true" tabindex="-1"></a>        mutated[idx_to_replace] <span class="op">=</span> new_feature</span>
<span id="cb35-105"><a href="#cb35-105" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mutated</span>
<span id="cb35-106"><a href="#cb35-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-107"><a href="#cb35-107" aria-hidden="true" tabindex="-1"></a>initial_prob <span class="op">=</span> np.ones(<span class="bu">len</span>(feature_names)) <span class="op">/</span> <span class="bu">len</span>(feature_names)</span>
<span id="cb35-108"><a href="#cb35-108" aria-hidden="true" tabindex="-1"></a>population <span class="op">=</span> generate_population(initial_prob, config[<span class="st">"population_size"</span>])</span>
<span id="cb35-109"><a href="#cb35-109" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb35-110"><a href="#cb35-110" aria-hidden="true" tabindex="-1"></a>accuracy_history <span class="op">=</span> []</span>
<span id="cb35-111"><a href="#cb35-111" aria-hidden="true" tabindex="-1"></a>f1_history <span class="op">=</span> []</span>
<span id="cb35-112"><a href="#cb35-112" aria-hidden="true" tabindex="-1"></a>best_y_test, best_y_pred <span class="op">=</span> <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb35-113"><a href="#cb35-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-114"><a href="#cb35-114" aria-hidden="true" tabindex="-1"></a><span class="co"># === EVOLUCIÓN ===</span></span>
<span id="cb35-115"><a href="#cb35-115" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> gen <span class="kw">in</span> <span class="bu">range</span>(config[<span class="st">"num_generations"</span>]):</span>
<span id="cb35-116"><a href="#cb35-116" aria-hidden="true" tabindex="-1"></a>    gen_results <span class="op">=</span> []</span>
<span id="cb35-117"><a href="#cb35-117" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> subset <span class="kw">in</span> population:</span>
<span id="cb35-118"><a href="#cb35-118" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Filtrado con NaiveBayes para descartar malas combinaciones</span></span>
<span id="cb35-119"><a href="#cb35-119" aria-hidden="true" tabindex="-1"></a>        acc_nb, _, _, _ <span class="op">=</span> evaluate_subset(subset, GaussianNB())</span>
<span id="cb35-120"><a href="#cb35-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> acc_nb <span class="op">&lt;</span> <span class="fl">0.5</span>:</span>
<span id="cb35-121"><a href="#cb35-121" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb35-122"><a href="#cb35-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-123"><a href="#cb35-123" aria-hidden="true" tabindex="-1"></a>        clf <span class="op">=</span> get_classifier(config[<span class="st">"classifier_name"</span>], config[<span class="st">"random_state"</span>])</span>
<span id="cb35-124"><a href="#cb35-124" aria-hidden="true" tabindex="-1"></a>        acc_rf, f1_rf, y_test, y_pred <span class="op">=</span> evaluate_subset(subset, clf)</span>
<span id="cb35-125"><a href="#cb35-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-126"><a href="#cb35-126" aria-hidden="true" tabindex="-1"></a>        gen_results.append({</span>
<span id="cb35-127"><a href="#cb35-127" aria-hidden="true" tabindex="-1"></a>            <span class="st">"experiment_id"</span>: config[<span class="st">"experiment_id"</span>],</span>
<span id="cb35-128"><a href="#cb35-128" aria-hidden="true" tabindex="-1"></a>            <span class="st">"generation"</span>: gen <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb35-129"><a href="#cb35-129" aria-hidden="true" tabindex="-1"></a>            <span class="st">"features"</span>: subset,</span>
<span id="cb35-130"><a href="#cb35-130" aria-hidden="true" tabindex="-1"></a>            <span class="st">"accuracy"</span>: acc_rf,</span>
<span id="cb35-131"><a href="#cb35-131" aria-hidden="true" tabindex="-1"></a>            <span class="st">"f1_score"</span>: f1_rf,</span>
<span id="cb35-132"><a href="#cb35-132" aria-hidden="true" tabindex="-1"></a>            <span class="st">"subset_size"</span>: <span class="bu">len</span>(subset),</span>
<span id="cb35-133"><a href="#cb35-133" aria-hidden="true" tabindex="-1"></a>            <span class="st">"classifier"</span>: config[<span class="st">"classifier_name"</span>]</span>
<span id="cb35-134"><a href="#cb35-134" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb35-135"><a href="#cb35-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-136"><a href="#cb35-136" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> gen_results:</span>
<span id="cb35-137"><a href="#cb35-137" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb35-138"><a href="#cb35-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-139"><a href="#cb35-139" aria-hidden="true" tabindex="-1"></a>    gen_results.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">"accuracy"</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb35-140"><a href="#cb35-140" aria-hidden="true" tabindex="-1"></a>    elite_count <span class="op">=</span> <span class="bu">max</span>(<span class="dv">1</span>, <span class="bu">int</span>(config[<span class="st">"elite_fraction"</span>] <span class="op">*</span> <span class="bu">len</span>(gen_results)))</span>
<span id="cb35-141"><a href="#cb35-141" aria-hidden="true" tabindex="-1"></a>    elites <span class="op">=</span> gen_results[:elite_count]</span>
<span id="cb35-142"><a href="#cb35-142" aria-hidden="true" tabindex="-1"></a>    results.extend(elites)</span>
<span id="cb35-143"><a href="#cb35-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-144"><a href="#cb35-144" aria-hidden="true" tabindex="-1"></a>    accuracy_history.append(elites[<span class="dv">0</span>][<span class="st">"accuracy"</span>])</span>
<span id="cb35-145"><a href="#cb35-145" aria-hidden="true" tabindex="-1"></a>    f1_history.append(elites[<span class="dv">0</span>][<span class="st">"f1_score"</span>])</span>
<span id="cb35-146"><a href="#cb35-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-147"><a href="#cb35-147" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> elites[<span class="dv">0</span>][<span class="st">"accuracy"</span>] <span class="op">&gt;=</span> <span class="bu">max</span>(accuracy_history):</span>
<span id="cb35-148"><a href="#cb35-148" aria-hidden="true" tabindex="-1"></a>        best_y_test, best_y_pred <span class="op">=</span> y_test, y_pred</span>
<span id="cb35-149"><a href="#cb35-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-150"><a href="#cb35-150" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Gen </span><span class="sc">{</span>gen<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>config[<span class="st">'num_generations'</span>]<span class="sc">}</span><span class="ss">: Mejor Accuracy = </span><span class="sc">{</span>elites[<span class="dv">0</span>][<span class="st">'accuracy'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb35-151"><a href="#cb35-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-152"><a href="#cb35-152" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Actualizar distribución de probabilidad según frecuencia de features en elites</span></span>
<span id="cb35-153"><a href="#cb35-153" aria-hidden="true" tabindex="-1"></a>    feature_counter <span class="op">=</span> Counter()</span>
<span id="cb35-154"><a href="#cb35-154" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> elite <span class="kw">in</span> elites:</span>
<span id="cb35-155"><a href="#cb35-155" aria-hidden="true" tabindex="-1"></a>        feature_counter.update(elite[<span class="st">"features"</span>])</span>
<span id="cb35-156"><a href="#cb35-156" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="bu">sum</span>(feature_counter.values())</span>
<span id="cb35-157"><a href="#cb35-157" aria-hidden="true" tabindex="-1"></a>    prob_dist <span class="op">=</span> np.array([feature_counter.get(f, <span class="dv">0</span>) <span class="op">/</span> total <span class="cf">for</span> f <span class="kw">in</span> feature_names])</span>
<span id="cb35-158"><a href="#cb35-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-159"><a href="#cb35-159" aria-hidden="true" tabindex="-1"></a>    new_population <span class="op">=</span> []</span>
<span id="cb35-160"><a href="#cb35-160" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(new_population) <span class="op">&lt;</span> config[<span class="st">"population_size"</span>]:</span>
<span id="cb35-161"><a href="#cb35-161" aria-hidden="true" tabindex="-1"></a>        base_subset <span class="op">=</span> random.choice(elites)[<span class="st">"features"</span>]</span>
<span id="cb35-162"><a href="#cb35-162" aria-hidden="true" tabindex="-1"></a>        mutated_subset <span class="op">=</span> mutate(base_subset)</span>
<span id="cb35-163"><a href="#cb35-163" aria-hidden="true" tabindex="-1"></a>        new_population.append(mutated_subset)</span>
<span id="cb35-164"><a href="#cb35-164" aria-hidden="true" tabindex="-1"></a>    population <span class="op">=</span> new_population</span>
<span id="cb35-165"><a href="#cb35-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-166"><a href="#cb35-166" aria-hidden="true" tabindex="-1"></a><span class="co"># === RESULTADOS ===</span></span>
<span id="cb35-167"><a href="#cb35-167" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb35-168"><a href="#cb35-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-169"><a href="#cb35-169" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar evolución accuracy y f1</span></span>
<span id="cb35-170"><a href="#cb35-170" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb35-171"><a href="#cb35-171" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(accuracy_history)<span class="op">+</span><span class="dv">1</span>), accuracy_history, label<span class="op">=</span><span class="st">"Accuracy"</span>, marker<span class="op">=</span><span class="st">"o"</span>)</span>
<span id="cb35-172"><a href="#cb35-172" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(f1_history)<span class="op">+</span><span class="dv">1</span>), f1_history, label<span class="op">=</span><span class="st">"F1-Score"</span>, marker<span class="op">=</span><span class="st">"x"</span>)</span>
<span id="cb35-173"><a href="#cb35-173" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Generación"</span>)</span>
<span id="cb35-174"><a href="#cb35-174" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Score"</span>)</span>
<span id="cb35-175"><a href="#cb35-175" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Evolución de Métricas"</span>)</span>
<span id="cb35-176"><a href="#cb35-176" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb35-177"><a href="#cb35-177" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb35-178"><a href="#cb35-178" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb35-179"><a href="#cb35-179" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb35-180"><a href="#cb35-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-181"><a href="#cb35-181" aria-hidden="true" tabindex="-1"></a><span class="co"># Imprimir matriz de confusión y reporte clasificación del mejor resultado</span></span>
<span id="cb35-182"><a href="#cb35-182" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_y_test <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> best_y_pred <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb35-183"><a href="#cb35-183" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">✅ Matriz de Confusión del Mejor Subconjunto:"</span>)</span>
<span id="cb35-184"><a href="#cb35-184" aria-hidden="true" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(best_y_test, best_y_pred)</span>
<span id="cb35-185"><a href="#cb35-185" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(cm)</span>
<span id="cb35-186"><a href="#cb35-186" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📋 Reporte de Clasificación:"</span>)</span>
<span id="cb35-187"><a href="#cb35-187" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(classification_report(best_y_test, best_y_pred))</span>
<span id="cb35-188"><a href="#cb35-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-189"><a href="#cb35-189" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">5</span>))</span>
<span id="cb35-190"><a href="#cb35-190" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb35-191"><a href="#cb35-191" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Matriz de Confusión - Mejor Modelo"</span>)</span>
<span id="cb35-192"><a href="#cb35-192" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Predicción"</span>)</span>
<span id="cb35-193"><a href="#cb35-193" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Real"</span>)</span>
<span id="cb35-194"><a href="#cb35-194" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb35-195"><a href="#cb35-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-196"><a href="#cb35-196" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar top 5 mejores subconjuntos ordenados por accuracy</span></span>
<span id="cb35-197"><a href="#cb35-197" aria-hidden="true" tabindex="-1"></a>top_results <span class="op">=</span> results_df.sort_values(by<span class="op">=</span><span class="st">"accuracy"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">5</span>)</span>
<span id="cb35-198"><a href="#cb35-198" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🔝 Top 5 subconjuntos con mayor accuracy:"</span>)</span>
<span id="cb35-199"><a href="#cb35-199" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_results[[<span class="st">"generation"</span>, <span class="st">"accuracy"</span>, <span class="st">"f1_score"</span>, <span class="st">"subset_size"</span>]])</span>
<span id="cb35-200"><a href="#cb35-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-201"><a href="#cb35-201" aria-hidden="true" tabindex="-1"></a><span class="co"># Contar frecuencia de características en top 5 subconjuntos</span></span>
<span id="cb35-202"><a href="#cb35-202" aria-hidden="true" tabindex="-1"></a>top_features_counter <span class="op">=</span> Counter()</span>
<span id="cb35-203"><a href="#cb35-203" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> features_list <span class="kw">in</span> top_results[<span class="st">"features"</span>]:</span>
<span id="cb35-204"><a href="#cb35-204" aria-hidden="true" tabindex="-1"></a>    top_features_counter.update(features_list)</span>
<span id="cb35-205"><a href="#cb35-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-206"><a href="#cb35-206" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Características seleccionadas en los 5 mejores subconjuntos ordenadas por frecuencia:"</span>)</span>
<span id="cb35-207"><a href="#cb35-207" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feat, freq <span class="kw">in</span> top_features_counter.most_common():</span>
<span id="cb35-208"><a href="#cb35-208" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>feat<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>freq<span class="sc">}</span><span class="ss"> veces"</span>)</span>
<span id="cb35-209"><a href="#cb35-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-210"><a href="#cb35-210" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb35-211"><a href="#cb35-211" aria-hidden="true" tabindex="-1"></a>top_freq_df <span class="op">=</span> pd.DataFrame.from_dict(top_features_counter, orient<span class="op">=</span><span class="st">'index'</span>, columns<span class="op">=</span>[<span class="st">"frequency"</span>])</span>
<span id="cb35-212"><a href="#cb35-212" aria-hidden="true" tabindex="-1"></a>top_freq_df <span class="op">=</span> top_freq_df.sort_values(by<span class="op">=</span><span class="st">"frequency"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb35-213"><a href="#cb35-213" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>top_freq_df.index, y<span class="op">=</span><span class="st">"frequency"</span>, data<span class="op">=</span>top_freq_df)</span>
<span id="cb35-214"><a href="#cb35-214" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb35-215"><a href="#cb35-215" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Frecuencia de Selección de Características en Top 5 Subconjuntos"</span>)</span>
<span id="cb35-216"><a href="#cb35-216" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Características"</span>)</span>
<span id="cb35-217"><a href="#cb35-217" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frecuencia"</span>)</span>
<span id="cb35-218"><a href="#cb35-218" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb35-219"><a href="#cb35-219" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb35-220"><a href="#cb35-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-221"><a href="#cb35-221" aria-hidden="true" tabindex="-1"></a><span class="co"># Frecuencia total de características en todos los resultados</span></span>
<span id="cb35-222"><a href="#cb35-222" aria-hidden="true" tabindex="-1"></a>feature_counter <span class="op">=</span> Counter()</span>
<span id="cb35-223"><a href="#cb35-223" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> results_df[<span class="st">"features"</span>]:</span>
<span id="cb35-224"><a href="#cb35-224" aria-hidden="true" tabindex="-1"></a>    feature_counter.update(row)</span>
<span id="cb35-225"><a href="#cb35-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-226"><a href="#cb35-226" aria-hidden="true" tabindex="-1"></a>freq_df <span class="op">=</span> pd.DataFrame.from_dict(feature_counter, orient<span class="op">=</span><span class="st">'index'</span>, columns<span class="op">=</span>[<span class="st">"frequency"</span>])</span>
<span id="cb35-227"><a href="#cb35-227" aria-hidden="true" tabindex="-1"></a>freq_df <span class="op">=</span> freq_df.sort_values(by<span class="op">=</span><span class="st">"frequency"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb35-228"><a href="#cb35-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-229"><a href="#cb35-229" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb35-230"><a href="#cb35-230" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>freq_df.index, y<span class="op">=</span><span class="st">"frequency"</span>, data<span class="op">=</span>freq_df)</span>
<span id="cb35-231"><a href="#cb35-231" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb35-232"><a href="#cb35-232" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Frecuencia de Selección de Características (Total)"</span>)</span>
<span id="cb35-233"><a href="#cb35-233" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Características"</span>)</span>
<span id="cb35-234"><a href="#cb35-234" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frecuencia"</span>)</span>
<span id="cb35-235"><a href="#cb35-235" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb35-236"><a href="#cb35-236" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb35-237"><a href="#cb35-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-238"><a href="#cb35-238" aria-hidden="true" tabindex="-1"></a>best_result <span class="op">=</span> results_df.loc[results_df[<span class="st">'accuracy'</span>].idxmax()]</span>
<span id="cb35-239"><a href="#cb35-239" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">✅ Mejor subconjunto de características:"</span>)</span>
<span id="cb35-240"><a href="#cb35-240" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>best_result[<span class="st">'accuracy'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb35-241"><a href="#cb35-241" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Características seleccionadas (ordenadas por frecuencia global):"</span>)</span>
<span id="cb35-242"><a href="#cb35-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-243"><a href="#cb35-243" aria-hidden="true" tabindex="-1"></a>best_feats <span class="op">=</span> best_result[<span class="st">'features'</span>]</span>
<span id="cb35-244"><a href="#cb35-244" aria-hidden="true" tabindex="-1"></a>best_feats_sorted <span class="op">=</span> <span class="bu">sorted</span>(best_feats, key<span class="op">=</span><span class="kw">lambda</span> f: feature_counter.get(f, <span class="dv">0</span>), reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb35-245"><a href="#cb35-245" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_feats_sorted)</span>
<span id="cb35-246"><a href="#cb35-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-247"><a href="#cb35-247" aria-hidden="true" tabindex="-1"></a>summary <span class="op">=</span> results_df.groupby(<span class="st">"experiment_id"</span>).agg({</span>
<span id="cb35-248"><a href="#cb35-248" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classifier"</span>: <span class="st">"first"</span>,</span>
<span id="cb35-249"><a href="#cb35-249" aria-hidden="true" tabindex="-1"></a>    <span class="st">"accuracy"</span>: [<span class="st">"max"</span>, <span class="st">"mean"</span>],</span>
<span id="cb35-250"><a href="#cb35-250" aria-hidden="true" tabindex="-1"></a>    <span class="st">"f1_score"</span>: <span class="st">"mean"</span>,</span>
<span id="cb35-251"><a href="#cb35-251" aria-hidden="true" tabindex="-1"></a>    <span class="st">"subset_size"</span>: <span class="st">"mean"</span>,</span>
<span id="cb35-252"><a href="#cb35-252" aria-hidden="true" tabindex="-1"></a>    <span class="st">"generation"</span>: <span class="st">"count"</span></span>
<span id="cb35-253"><a href="#cb35-253" aria-hidden="true" tabindex="-1"></a>}).reset_index()</span>
<span id="cb35-254"><a href="#cb35-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-255"><a href="#cb35-255" aria-hidden="true" tabindex="-1"></a>summary.columns <span class="op">=</span> [</span>
<span id="cb35-256"><a href="#cb35-256" aria-hidden="true" tabindex="-1"></a>    <span class="st">"experiment_id"</span>, <span class="st">"classifier"</span>, <span class="st">"max_accuracy"</span>, <span class="st">"mean_accuracy"</span>,</span>
<span id="cb35-257"><a href="#cb35-257" aria-hidden="true" tabindex="-1"></a>    <span class="st">"mean_f1_score"</span>, <span class="st">"mean_subset_size"</span>, <span class="st">"total_generations"</span></span>
<span id="cb35-258"><a href="#cb35-258" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb35-259"><a href="#cb35-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-260"><a href="#cb35-260" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Tabla de resultados acumulados:"</span>)</span>
<span id="cb35-261"><a href="#cb35-261" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary)</span>
<span id="cb35-262"><a href="#cb35-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-263"><a href="#cb35-263" aria-hidden="true" tabindex="-1"></a>history_df <span class="op">=</span> pd.concat([history_df, results_df], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb35-264"><a href="#cb35-264" aria-hidden="true" tabindex="-1"></a>history_df.to_csv(history_file, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Gen 1/50: Mejor Accuracy = 0.8854
Gen 2/50: Mejor Accuracy = 0.8854
Gen 3/50: Mejor Accuracy = 0.8896
Gen 4/50: Mejor Accuracy = 0.8896
Gen 5/50: Mejor Accuracy = 0.8896
Gen 6/50: Mejor Accuracy = 0.8896
Gen 7/50: Mejor Accuracy = 0.8896
Gen 8/50: Mejor Accuracy = 0.8958
Gen 9/50: Mejor Accuracy = 0.8896
Gen 10/50: Mejor Accuracy = 0.8896
Gen 11/50: Mejor Accuracy = 0.8896
Gen 12/50: Mejor Accuracy = 0.8917
Gen 13/50: Mejor Accuracy = 0.8917
Gen 14/50: Mejor Accuracy = 0.8917
Gen 15/50: Mejor Accuracy = 0.8917
Gen 16/50: Mejor Accuracy = 0.8917
Gen 17/50: Mejor Accuracy = 0.8979
Gen 18/50: Mejor Accuracy = 0.8979
Gen 19/50: Mejor Accuracy = 0.9042
Gen 20/50: Mejor Accuracy = 0.9042
Gen 21/50: Mejor Accuracy = 0.9042
Gen 22/50: Mejor Accuracy = 0.9042
Gen 23/50: Mejor Accuracy = 0.9042
Gen 24/50: Mejor Accuracy = 0.9042
Gen 25/50: Mejor Accuracy = 0.9042
Gen 26/50: Mejor Accuracy = 0.9042
Gen 27/50: Mejor Accuracy = 0.9042
Gen 28/50: Mejor Accuracy = 0.9042
Gen 29/50: Mejor Accuracy = 0.9042
Gen 30/50: Mejor Accuracy = 0.9042
Gen 31/50: Mejor Accuracy = 0.9042
Gen 32/50: Mejor Accuracy = 0.9083
Gen 33/50: Mejor Accuracy = 0.9083
Gen 34/50: Mejor Accuracy = 0.9083
Gen 35/50: Mejor Accuracy = 0.9083
Gen 36/50: Mejor Accuracy = 0.9083
Gen 37/50: Mejor Accuracy = 0.9104
Gen 38/50: Mejor Accuracy = 0.9104
Gen 39/50: Mejor Accuracy = 0.9104
Gen 40/50: Mejor Accuracy = 0.9104
Gen 41/50: Mejor Accuracy = 0.9104
Gen 42/50: Mejor Accuracy = 0.9104
Gen 43/50: Mejor Accuracy = 0.9104
Gen 44/50: Mejor Accuracy = 0.9104
Gen 45/50: Mejor Accuracy = 0.9104
Gen 46/50: Mejor Accuracy = 0.9104
Gen 47/50: Mejor Accuracy = 0.9104
Gen 48/50: Mejor Accuracy = 0.9104
Gen 49/50: Mejor Accuracy = 0.9104
Gen 50/50: Mejor Accuracy = 0.9104</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-13-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
✅ Matriz de Confusión del Mejor Subconjunto:
[[208  30]
 [ 13 229]]

📋 Reporte de Clasificación:
              precision    recall  f1-score   support

     Dropout       0.94      0.87      0.91       238
    Graduate       0.88      0.95      0.91       242

    accuracy                           0.91       480
   macro avg       0.91      0.91      0.91       480
weighted avg       0.91      0.91      0.91       480
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-13-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
🔝 Top 5 subconjuntos con mayor accuracy:
     generation  accuracy  f1_score  subset_size
175          44  0.910417  0.910278           10
174          44  0.910417  0.910278           10
173          44  0.910417  0.910278           10
172          44  0.910417  0.910278           10
171          43  0.910417  0.910278           10

Características seleccionadas en los 5 mejores subconjuntos ordenadas por frecuencia:
feature_30: 5 veces
feature_23: 5 veces
feature_14: 5 veces
feature_11: 5 veces
feature_16: 5 veces
feature_3: 5 veces
feature_7: 5 veces
feature_13: 5 veces
feature_22: 5 veces
feature_15: 5 veces</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-13-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2DO_EDAS_JOSE_PRUEBABASESDATOS_files/figure-html/cell-13-output-7.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
✅ Mejor subconjunto de características:
Accuracy: 0.9104
Características seleccionadas (ordenadas por frecuencia global):
[np.str_('feature_30'), np.str_('feature_23'), np.str_('feature_16'), np.str_('feature_13'), np.str_('feature_11'), 'feature_7', 'feature_3', 'feature_14', 'feature_22', 'feature_15']

📊 Tabla de resultados acumulados:
   experiment_id    classifier  max_accuracy  mean_accuracy  mean_f1_score  \
0              1  RandomForest      0.910417        0.90075       0.900562   

   mean_subset_size  total_generations  
0             9.955                200  </code></pre>
</div>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>