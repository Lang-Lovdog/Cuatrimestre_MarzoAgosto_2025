* Bayes Naïve
  Primero, se supone que existen dos eventos posibles.
  Se recurre a la relación Bayesiana de probabilidad concional.
  $P(A|B) = \frac{P(B|A)P(A)}{P(B)}$

  Bayes Naïve ignora la probabilidad de B (ya que en la comparación, el factor no afecta el resultado).
  $P(A|B) = P(B|A)P(A)$

  Considerando a B la variable de características y A la variable de clases.
  Para obtener la probabilidad conjunta crea una expresión más compleja.
  Para evitar la complejidad de la probabilidad conjunta, se consideran como independientes todos los elementos de B.
  Finalmente se obtiene:
  $|\frac{argmax}{k\in {1,...,k}} P(A_{k}) \prod_{i=1}^{n} P(B_{i}|A_{k})|$
  
  En este supuesto, persiste un problema que puede tropezar el resultado probabilístico. Para evitarlo, se procede a aplicar logaritmos en las probabilidades.
  $|\frac{argmax}{k\in {1,...,k}} log\left(P(A_{k})\right) \sum_{i=1}^{n} log\left(P(B_{i}|A_{k})\right)|$
  @math
  \frac{argmax}{k\in {1,...,k}} log\left(P(A_{k})\right) \sum_{i=1}^{n} log\left(P(B_{i}|A_{k})\right)
  @end

<<<

* Métricas de evaluación del desempeño
  Matriz de confusión clasifica las predicciones a traves de
** True Positive
** True Negative
** False Postive
** False Negative

* Exactitud (accuracy)
* Precisión (precision)
* Sensibilidad  (Tasa de verdaderos positivo)
* Especificidad (Tasa de falsos positivos)
* Puntaje F1
  Preferente al tener una base desbalanceada.
* Curvas ROC
  Eje X: Especificidad
  Eje Y: Sensibilidad
  Esta curva debe estar por encima de la diagonal principal.

  En python existe una biblioteca que permite calcularla
  {https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html}[ROC Curve SCIKit-Learn]
  
  El área bajo dicha curva es un indicador de sensibilidad del clasificador.
  Aquí se obtiene desde el inicio hasta el punto /threshold/.
