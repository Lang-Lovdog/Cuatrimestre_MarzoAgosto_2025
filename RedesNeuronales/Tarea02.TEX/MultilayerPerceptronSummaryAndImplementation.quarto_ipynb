{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Multilayer Perceptron Summary and Implementation\"\n",
        "execute:\n",
        "   enabled: true\n",
        "format:\n",
        "   pdf:\n",
        "     title: Multilayer Perceptron Summary and Implementation\n",
        "     author: Brandon Marquez Salazar\n",
        "     pdf-engine: pdflatex\n",
        "     documentclass: IEEEtran\n",
        "     number-sections: true\n",
        "     bibliography: bibliography.bib\n",
        "     bibliographystyle: ieee\n",
        "     nocite: |\n",
        "      @*\n",
        "     cite-method: biblatex\n",
        "     include-in-header:\n",
        "       - text: |\n",
        "           \\usepackage{dirtytalk}\n",
        "           \\usepackage{tikz}\n",
        "           \\usetikzlibrary{positioning}\n",
        "           \\tikzset{\n",
        "             x=2.8em,\n",
        "             y=2.8em,\n",
        "           }\n",
        "           \\input{Macros}\n",
        "jupyter: redesneuronales\n",
        "---\n",
        "\n",
        "# Introduction\n",
        "\n",
        "A perceptron is a simple neuron which computes a value and thresholds it\n",
        "through an activation function. This neuron has the ability to learn\n",
        "from any given input and it's expected output using a simple iterative process\n",
        "of training. This training process alters  the coefficients of a weighed\n",
        "symbolic vector, which weights are used to compute a desired output and the\n",
        "values of the vector variables are the given inputs.\n",
        "This approach came from mathematical interpretation a brain cell's behavior,\n",
        "and its _tout seule_ implementation is limited to linearly separable problems.\n",
        "\n",
        "\n",
        "# Artificial Neural Network and Multilayer Perceptron\n",
        "\n",
        "An artificial neural network, ANN, is an elements net. Those elements\n",
        "(neurons) which are connected one to each other. Those nodes are organized\n",
        "in layers. There are three main types of layers:\n",
        "\n",
        "  * Input layer: This layer is the one that receives the input data.\n",
        "  * Hidden layer: The output of the neurons in this layer is not visible.\n",
        "  * Output layer: This layer outputs the final values.\n",
        "\n",
        "A **Multilayer Perceptron** MLP  is a static artificial neural network\n",
        "architecture where each node in a layer is connected to every node in the next\n",
        "layer.\n",
        "\n",
        "```{=latex}\n",
        "\\begin{center}\n",
        "\\input{./MLP_TIKZ_Diag}\n",
        "\\end{center}\n",
        "```\n",
        "\n",
        "# Backpropagation Algorithm\n",
        "\n",
        "Backpropagation is an algorithm used to train an ANN, this algorithm is a\n",
        "generalization of the gradient descent algorithm following the steps below:\n",
        "\n",
        "  1. Initialize the weights of the network at small random values.\n",
        "  2. Forward computation $\\forall i$-th training pair ($x_i$, $o_i$)\n",
        "     * $\\forall n$-th neuron and each $k$-th neuron input, compute the input and output\n",
        "       $$v_{nk};\\; o_{nk} = f(v_{nk})$$\n",
        "  3. Backward computation start computing from output layer\n",
        "     * $\\forall n$-th neuron and each $k$-th neuron input, update weights\n",
        "       $$w_{nk} = w_{nk} + \\Delta w_{nk} $$"
      ],
      "id": "5b0673e8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "redesneuronales",
      "language": "python",
      "display_name": "redesneuronales",
      "path": "/home/lang_lovdog/.local/share/jupyter/kernels/redesneuronales"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}